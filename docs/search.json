[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "PSYC 859 Syllabus",
    "section": "",
    "text": "This graduate course is intended to provide an applied introduction to data management and data visualization in the social sciences. In order to take full advantage of modern statistical methods (e.g., structural equation models), competency in data management, semi-automated processing, and data wrangling is prerequisite. Likewise, prior to employing inferential statistics, exploratory visualization and analysis is essential to facilitate data cleaning and to form an initial understanding of patterns in the data. This course will cover both the principles and practice of data management, visualization, and exploratory analysis for summarizing quantitative data. In addition, students will learn data science skills to manage and visualize “big data,” where the size or complexity of the dataset defies traditional techniques.\nApplications of data management, visualization, and analysis will use the R statistical programming language. R is quickly becoming the lingua franca in data science across disciplines and offers unparalleled tools for data analysis and visualization."
  },
  {
    "objectID": "syllabus.html#week-1",
    "href": "syllabus.html#week-1",
    "title": "PSYC 859 Syllabus",
    "section": "Week 1 (1/8): Introduction to data management and tidy data",
    "text": "Week 1 (1/8): Introduction to data management and tidy data\n\nConceptual readings\n\nBriney, K., Coates, H., & Goben, A. (2020). Foundational Practices of Research Data Management. Research Ideas and Outcomes, 6, e56508. https://doi.org/10.3897/rio.6.e56508\nBorer, E. T., Seabloom, E. W., Jones, M. B., & Schildhauer, M. (2009). Some Simple Guidelines for Effective Data Management. The Bulletin of the Ecological Society of America, 90, 205-214. https://doi.org/10.1890/0012-9623-90.2.205\n(Optional) Borghi, J. A., & Gulick, A. E. V. (2021). Data management and sharing: Practices and perceptions of psychology researchers. PLOS ONE, 16, e0252047. https://doi.org/10.1371/journal.pone.0252047\n\n\n\nPractical readings\n\nWickham, H., Cetinka-Rundel, M., & Grolemund, G. (2023). R for Data Science (2nd ed.).\n\nCh. 2: Workflow: basics. https://r4ds.hadley.nz/workflow-basics.html\nCh. 4: Workflow: code style. https://r4ds.hadley.nz/workflow-style.html\nCh. 5: Data tidying. https://r4ds.hadley.nz/data-tidy.html\nCh. 6: Workflow: scripts and projects. https://r4ds.hadley.nz/workflow-scripts.html\nCh. 7: Data import. https://r4ds.hadley.nz/data-import.html\n\n(Supplementary) Tidyr pivoting vignette: https://tidyr.tidyverse.org/articles/pivot.html\nTidyr cheatsheet: https://rstudio.github.io/cheatsheets/tidyr.pdf\nRStudio Data Import cheat sheet: https://rstudio.github.io/cheatsheets/data-import.pdf"
  },
  {
    "objectID": "syllabus.html#week-2",
    "href": "syllabus.html#week-2",
    "title": "PSYC 859 Syllabus",
    "section": "Week 2 (1/15): Data aggregation, manipulation, joins",
    "text": "Week 2 (1/15): Data aggregation, manipulation, joins\n\nPractical readings\n\nWickham, H., Cetinka-Rundel, M., & Grolemund, G. (2023). R for Data Science (2nd ed.).\n\nCh. 3: Data transformation: https://r4ds.hadley.nz/data-transform.html\nCh. 12: Logical vectors: https://r4ds.hadley.nz/logicals.html\nCh. 13: Numbers: https://r4ds.hadley.nz/numbers.html\nCh. 14: Strings: https://r4ds.hadley.nz/strings.html\nCh. 16: Factors: https://r4ds.hadley.nz/factors.html\nCh. 19: Joins: https://r4ds.hadley.nz/joins.html\n(Optional) Ch. 15: Regular expressions. https://r4ds.hadley.nz/regexps.html\n(Optional) Ch. 17: Dates and times. https://r4ds.hadley.nz/datetimes.html\n(Optional) Ch. 20: Import: spreadsheets. https://r4ds.hadley.nz/spreadsheets.html"
  },
  {
    "objectID": "syllabus.html#week-3",
    "href": "syllabus.html#week-3",
    "title": "PSYC 859 Syllabus",
    "section": "Week 3 (1/22): Data processing and quality assurance, custom functions, basics of automation",
    "text": "Week 3 (1/22): Data processing and quality assurance, custom functions, basics of automation"
  },
  {
    "objectID": "syllabus.html#week-4",
    "href": "syllabus.html#week-4",
    "title": "PSYC 859 Syllabus",
    "section": "Week 4 (1/29): Advanced data manipulation and management, tracking work in R markdown",
    "text": "Week 4 (1/29): Advanced data manipulation and management, tracking work in R markdown"
  },
  {
    "objectID": "syllabus.html#week-5",
    "href": "syllabus.html#week-5",
    "title": "PSYC 859 Syllabus",
    "section": "Week 5 (2/5): Principles of data visualization and graphical grammar",
    "text": "Week 5 (2/5): Principles of data visualization and graphical grammar"
  },
  {
    "objectID": "syllabus.html#week-6",
    "href": "syllabus.html#week-6",
    "title": "PSYC 859 Syllabus",
    "section": "Week 6 (2/12): Visual and graphical perception",
    "text": "Week 6 (2/12): Visual and graphical perception"
  },
  {
    "objectID": "syllabus.html#week-7",
    "href": "syllabus.html#week-7",
    "title": "PSYC 859 Syllabus",
    "section": "Week 7 (2/19): Graphic design, layout, style, use of color",
    "text": "Week 7 (2/19): Graphic design, layout, style, use of color"
  },
  {
    "objectID": "syllabus.html#week-8",
    "href": "syllabus.html#week-8",
    "title": "PSYC 859 Syllabus",
    "section": "Week 8 (2/26): A tour of quantitative visualization",
    "text": "Week 8 (2/26): A tour of quantitative visualization"
  },
  {
    "objectID": "syllabus.html#week-9",
    "href": "syllabus.html#week-9",
    "title": "PSYC 859 Syllabus",
    "section": "Week 9 (3/5): Visualizing continuous data (in ggplot2)",
    "text": "Week 9 (3/5): Visualizing continuous data (in ggplot2)"
  },
  {
    "objectID": "syllabus.html#week-10",
    "href": "syllabus.html#week-10",
    "title": "PSYC 859 Syllabus",
    "section": "Week 10 (3/12): Visualizing count and categorical data (in ggplot2)",
    "text": "Week 10 (3/12): Visualizing count and categorical data (in ggplot2)"
  },
  {
    "objectID": "syllabus.html#no-class-spring-break",
    "href": "syllabus.html#no-class-spring-break",
    "title": "PSYC 859 Syllabus",
    "section": "3/19: No class (Spring break)",
    "text": "3/19: No class (Spring break)"
  },
  {
    "objectID": "syllabus.html#week-11",
    "href": "syllabus.html#week-11",
    "title": "PSYC 859 Syllabus",
    "section": "Week 11 (3/26): Maximizing clarity: preparing graphics for presentation and publication",
    "text": "Week 11 (3/26): Maximizing clarity: preparing graphics for presentation and publication"
  },
  {
    "objectID": "syllabus.html#no-class-well-being-day",
    "href": "syllabus.html#no-class-well-being-day",
    "title": "PSYC 859 Syllabus",
    "section": "4/2: No class (Well-being day)",
    "text": "4/2: No class (Well-being day)"
  },
  {
    "objectID": "syllabus.html#week-12",
    "href": "syllabus.html#week-12",
    "title": "PSYC 859 Syllabus",
    "section": "Week 12 (4/9): Visualizing and understanding fit (and misfit) of statistical models",
    "text": "Week 12 (4/9): Visualizing and understanding fit (and misfit) of statistical models"
  },
  {
    "objectID": "syllabus.html#week-13",
    "href": "syllabus.html#week-13",
    "title": "PSYC 859 Syllabus",
    "section": "Week 13 (4/16): Exploratory statistics for understanding data: clustering, multidimensional scaling, dimension reduction",
    "text": "Week 13 (4/16): Exploratory statistics for understanding data: clustering, multidimensional scaling, dimension reduction"
  },
  {
    "objectID": "syllabus.html#week-14",
    "href": "syllabus.html#week-14",
    "title": "PSYC 859 Syllabus",
    "section": "Week 14 (4/23): Final presentations of data projects",
    "text": "Week 14 (4/23): Final presentations of data projects"
  },
  {
    "objectID": "syllabus.html#permitted-uses",
    "href": "syllabus.html#permitted-uses",
    "title": "PSYC 859 Syllabus",
    "section": "Permitted uses",
    "text": "Permitted uses\nStudents may use AI tools for the following purposes:\n\nDebugging code, including identifying syntax errors, logical errors, or unexpected behavior.\nRequesting explanations of how a piece of code works, why it produces a particular result, or why it fails.\nRequesting suggestions for code improvement, refactoring, or alternative approaches to a task.\n\nThese uses are consistent with how AI tools are used responsibly in real research workflows."
  },
  {
    "objectID": "syllabus.html#expectations-and-responsibilities",
    "href": "syllabus.html#expectations-and-responsibilities",
    "title": "PSYC 859 Syllabus",
    "section": "Expectations and responsibilities",
    "text": "Expectations and responsibilities\nWhen using AI tools, students are expected to:\n\nActively evaluate and understand any code they submit, regardless of its source.\nEnsure they can explain what the code does and why it works, including key functions, assumptions, and consequences.\nMake independent decisions about whether to adopt AI-suggested code, rather than copying it uncritically.\nRemain responsible for correctness, clarity, and reproducibility of all submitted work.\n\nSubmitting code that the student does not understand is inconsistent with the learning objectives of the course."
  },
  {
    "objectID": "syllabus.html#prohibited-uses",
    "href": "syllabus.html#prohibited-uses",
    "title": "PSYC 859 Syllabus",
    "section": "Prohibited uses",
    "text": "Prohibited uses\nThe following are not permitted:\n\nSubmitting AI-generated code or analyses without understanding or review.\nUsing AI tools as a substitute for engaging with core course concepts (e.g., visualization principles, data cleaning logic).\nRepresenting AI-generated work as understanding or reasoning that the student cannot demonstrate if asked."
  },
  {
    "objectID": "syllabus.html#transparency",
    "href": "syllabus.html#transparency",
    "title": "PSYC 859 Syllabus",
    "section": "Transparency",
    "text": "Transparency\nFor major assignments and the final project, students may be asked to include a brief AI use statement (1-3 sentences) describing whether and how AI tools were used (e.g., “used for debugging,” “used to explore alternative ggplot layouts”). This is not punitive; its purpose is to promote transparency and reflective practice."
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html",
    "href": "materials/w02_wrangling/joins_tutorial.html",
    "title": "Joins Tutorial",
    "section": "",
    "text": "This document has been adapted and extended by Michael Hallquist and Benjamin Johnson from Jenny Bryan’s dplyr joins tutorial (http://stat545.com/bit001_dplyr-cheatsheet.html). Animations were developed by Garrick Aden-Buie. The goal is to develop an intuition of the four major types of two-table join operations: inner, left, right, and full. We’ll also get into using joins to identify areas of match or mismatch between two datasets (using semi- and anti-joins).\n\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n\n\nStorm\ngood\nfemale\nMarvel\n\n\nMystique\nbad\nfemale\nMarvel\n\n\nBatman\ngood\nmale\nDC\n\n\nJoker\nbad\nmale\nDC\n\n\nCatwoman\nbad\nfemale\nDC\n\n\nHellboy\ngood\nmale\nDark Horse Comics\n\n\n\n\n\n\n\n\n\n\n\n\n\npublisher\nyr_founded\n\n\n\n\nDC\n1934\n\n\nMarvel\n1939\n\n\nImage\n1992"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#superheroes-table",
    "href": "materials/w02_wrangling/joins_tutorial.html#superheroes-table",
    "title": "Joins Tutorial",
    "section": "",
    "text": "name\nalignment\ngender\npublisher\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n\n\nStorm\ngood\nfemale\nMarvel\n\n\nMystique\nbad\nfemale\nMarvel\n\n\nBatman\ngood\nmale\nDC\n\n\nJoker\nbad\nmale\nDC\n\n\nCatwoman\nbad\nfemale\nDC\n\n\nHellboy\ngood\nmale\nDark Horse Comics"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#publishers-table",
    "href": "materials/w02_wrangling/joins_tutorial.html#publishers-table",
    "title": "Joins Tutorial",
    "section": "",
    "text": "publisher\nyr_founded\n\n\n\n\nDC\n1934\n\n\nMarvel\n1939\n\n\nImage\n1992"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#inner-join",
    "href": "materials/w02_wrangling/joins_tutorial.html#inner-join",
    "title": "Joins Tutorial",
    "section": "inner join",
    "text": "inner join\nRequire match in both datasets (non-matching rows are dropped)\nFor those of you who are visual learners, conceptually, imagine the following two simple datasets:\n\nAn inner join combines the two datasets and drops the non-matching rows like so:\n\nLet’s try it with our superhero data.\n\n\nCode\n#*NB*: Here, we retain the joined dataset as ijsp\nijsp &lt;- inner_join(x=superheroes, y=publishers)\nprint(ijsp)\n\n\n# A tibble: 6 × 5\n  name     alignment gender publisher yr_founded\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n1 Magneto  bad       male   Marvel          1939\n2 Storm    good      female Marvel          1939\n3 Mystique bad       female Marvel          1939\n4 Batman   good      male   DC              1934\n5 Joker    bad       male   DC              1934\n6 Catwoman bad       female DC              1934\n\n\nSame idea, just explicit declaration of key (i.e., “publisher”)\n\n\nCode\n#note that we've cut the x=, y= as this optional\ninner_join(superheroes, publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\nyr_founded\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n1939\n\n\nStorm\ngood\nfemale\nMarvel\n1939\n\n\nMystique\nbad\nfemale\nMarvel\n1939\n\n\nBatman\ngood\nmale\nDC\n1934\n\n\nJoker\nbad\nmale\nDC\n1934\n\n\nCatwoman\nbad\nfemale\nDC\n1934\n\n\n\n\n\n\nNotice both Hellboy (from the superheroes dataset) and Image comics (from the publishers dataset) were dropped."
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#left-join",
    "href": "materials/w02_wrangling/joins_tutorial.html#left-join",
    "title": "Joins Tutorial",
    "section": "left join",
    "text": "left join\nKeep all rows in left-hand ‘x’ dataset (i.e., superheroes). Add columns from publishers where there is a match. Fill in NA for non-matching observations.\n\n\n\nCode\nleft_join(superheroes, publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\nyr_founded\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n1939\n\n\nStorm\ngood\nfemale\nMarvel\n1939\n\n\nMystique\nbad\nfemale\nMarvel\n1939\n\n\nBatman\ngood\nmale\nDC\n1934\n\n\nJoker\nbad\nmale\nDC\n1934\n\n\nCatwoman\nbad\nfemale\nDC\n1934\n\n\nHellboy\ngood\nmale\nDark Horse Comics\nNA"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#right-join",
    "href": "materials/w02_wrangling/joins_tutorial.html#right-join",
    "title": "Joins Tutorial",
    "section": "right join",
    "text": "right join\nKeep all rows in right-hand ‘y’ dataset (i.e., publishers). Add columns from superheroes where there is a match. Fill in NA for non-matching observations.\n\n\n\nCode\n# Note the shift to using dplyr piping\n# This achieves the same purpose, but may be preferred by those who love pipes\nsuperheroes %&gt;% right_join(publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\nyr_founded\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n1939\n\n\nStorm\ngood\nfemale\nMarvel\n1939\n\n\nMystique\nbad\nfemale\nMarvel\n1939\n\n\nBatman\ngood\nmale\nDC\n1934\n\n\nJoker\nbad\nmale\nDC\n1934\n\n\nCatwoman\nbad\nfemale\nDC\n1934\n\n\nNA\nNA\nNA\nImage\n1992"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#full-join",
    "href": "materials/w02_wrangling/joins_tutorial.html#full-join",
    "title": "Joins Tutorial",
    "section": "full join",
    "text": "full join\nKeep all rows in left-hand ‘x’ (superheroes) and right-hand ‘y’ (publishers) datasets.\nResulting dataset will have all columns of both datasets, but filling in NA for any non-matches on either side (denoted as blank spaces below).\n\n\n\nCode\nsuperheroes %&gt;% full_join(publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\nyr_founded\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n1939\n\n\nStorm\ngood\nfemale\nMarvel\n1939\n\n\nMystique\nbad\nfemale\nMarvel\n1939\n\n\nBatman\ngood\nmale\nDC\n1934\n\n\nJoker\nbad\nmale\nDC\n1934\n\n\nCatwoman\nbad\nfemale\nDC\n1934\n\n\nHellboy\ngood\nmale\nDark Horse Comics\nNA\n\n\nNA\nNA\nNA\nImage\n1992"
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#semi_join",
    "href": "materials/w02_wrangling/joins_tutorial.html#semi_join",
    "title": "Joins Tutorial",
    "section": "semi_join",
    "text": "semi_join\nretain observations (rows) in x that match in y\n\n\nObservations in superheroes that match in publishers\nNotice that this is different from the left_join shown above as the data from y is not kept. That is the fundamental difference between ‘mutating joins’ (e.g., left_join) and ‘filtering joins’ (e.g., semi_join).\n\n\nCode\nsemi_join(superheroes, publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\n\n\n\n\nMagneto\nbad\nmale\nMarvel\n\n\nStorm\ngood\nfemale\nMarvel\n\n\nMystique\nbad\nfemale\nMarvel\n\n\nBatman\ngood\nmale\nDC\n\n\nJoker\nbad\nmale\nDC\n\n\nCatwoman\nbad\nfemale\nDC\n\n\n\n\n\n\n\n\nObservations in publishers that match in superheroes\n\n\nCode\nsemi_join(publishers, superheroes, by=\"publisher\")\n\n\n\n\n\n\npublisher\nyr_founded\n\n\n\n\nDC\n1934\n\n\nMarvel\n1939\n\n\n\n\n\n\nThis can be useful if you have a dataset of your data of interest and another dataset that indicates which of your participants/observations you want to remove or filter out."
  },
  {
    "objectID": "materials/w02_wrangling/joins_tutorial.html#anti_join",
    "href": "materials/w02_wrangling/joins_tutorial.html#anti_join",
    "title": "Joins Tutorial",
    "section": "anti_join",
    "text": "anti_join\nobservations in x that are not matched in y Note that this is similar to setdiff in base R\n\n\nObservations in superheroes that don’t match in publishers\n\n\nCode\nanti_join(superheroes, publishers, by=\"publisher\")\n\n\n\n\n\n\nname\nalignment\ngender\npublisher\n\n\n\n\nHellboy\ngood\nmale\nDark Horse Comics\n\n\n\n\n\n\n\n\nObservations in publishers that don’t match in superheroes\n\n\nCode\npublishers %&gt;% anti_join(superheroes, by=\"publisher\")\n\n\n\n\n\n\npublisher\nyr_founded\n\n\n\n\nImage\n1992\n\n\n\n\n\n\nThis can be useful if you are trying to identify extra participants/observations that may have snuck into one dataset (x) or been deleted in another (y)."
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html",
    "title": "Tidy data overview",
    "section": "",
    "text": "Most data wrangling can be accomplished using data.frame object (or tbl objects in dplyr). These objects consist of rows and columns, forming a rectangular structure.\n\n\nCode\ngapminder %&gt;% kable_table(n=6)\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.4453\n\n\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.8530\n\n\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.1007\n\n\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.1971\n\n\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.9811\n\n\nAfghanistan\nAsia\n1977\n38.438\n14880372\n786.1134\n\n\n\n\n\n\n\nA variable contains all values measuring an attribute (e.g., neuroticism) across units (e.g., people).\nColumns in data.frames are typically labeled and represent variables.\nMoreover, in a data.frame, all values in a given column should have the same data type, such as character strings. But a data.frame is different from a matrix object because columns can differ in terms of data type. For example, in the gapminder, the country column is a factor, whereas lifeExp is a numeric column.\n“A data frame is a list of vectors that R displays as a table. When your data is tidy, the values of each variable fall in their own column vector.” -Garrett Grolemund Citation\n\n\n\nAn observation contains all values measured on the same unit across attributes.\nRows in a data.frame typically represent observations.\n\n\nCode\ngapminder %&gt;% kable_table(n=1)\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.4453"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#variables",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#variables",
    "title": "Tidy data overview",
    "section": "",
    "text": "A variable contains all values measuring an attribute (e.g., neuroticism) across units (e.g., people).\nColumns in data.frames are typically labeled and represent variables.\nMoreover, in a data.frame, all values in a given column should have the same data type, such as character strings. But a data.frame is different from a matrix object because columns can differ in terms of data type. For example, in the gapminder, the country column is a factor, whereas lifeExp is a numeric column.\n“A data frame is a list of vectors that R displays as a table. When your data is tidy, the values of each variable fall in their own column vector.” -Garrett Grolemund Citation"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#observations",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#observations",
    "title": "Tidy data overview",
    "section": "",
    "text": "An observation contains all values measured on the same unit across attributes.\nRows in a data.frame typically represent observations.\n\n\nCode\ngapminder %&gt;% kable_table(n=1)\n\n\n\n\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\n\n\n\n\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.4453"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#tidying-verbs",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#tidying-verbs",
    "title": "Tidy data overview",
    "section": "Tidying verbs",
    "text": "Tidying verbs\nThe tidyr package provides four core functions to aid in converting messy data into tidy form. We may also need functions from dplyr at times. Each of these verbs is also a function that transforms the dataset with the goal of making it more tidy.\n\nPivot_longer: combine multiple columns into a single column with a key-value pair format\nPivot_wider: divide key-value rows into multiple columns\nSeparate: split a single variable into multiple variables by pulling apart the values into pieces\nUnite: merge two variables (columns) into one, effectively pasting together the values\n\nNote: pivot_longer and pivot_wider are complements. And separate and unite are complements.\nDetails about the pivot functions can be found here: https://tidyr.tidyverse.org/articles/pivot.html.\nLet’s look at a series of datasets (from Wickham 2014) and consider how tidy or messy they are."
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#pivot_longer-example",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#pivot_longer-example",
    "title": "Tidy data overview",
    "section": "pivot_longer example",
    "text": "pivot_longer example\nHere is our first mess. Notice that the column headers are values, not variable names. This is untidy and hard to look at. We effectively have the data in a cross-tabulated format, but religion and income are not variables in the dataset.\n\nMessy version\n\n\n\n\n\nreligion\n&lt;$10k\n$10-20k\n$20-30k\n$30-40k\n$40-50k\n$50-75k\n\n\n\n\nAgnostic\n27\n34\n60\n81\n76\n137\n\n\nAtheist\n12\n27\n37\n52\n35\n70\n\n\nBuddhist\n27\n21\n30\n34\n33\n58\n\n\nCatholic\n418\n617\n732\n670\n638\n1116\n\n\nDon’t know/refused\n15\n14\n15\n11\n10\n35\n\n\nEvangelical Prot\n575\n869\n1064\n982\n881\n1486\n\n\nHindu\n1\n9\n7\n9\n11\n34\n\n\nHistorically Black Prot\n228\n244\n236\n238\n197\n223\n\n\nJehovah's Witness\n20\n27\n24\n24\n21\n30\n\n\nJewish\n19\n19\n25\n25\n30\n95\n\n\n\n\n\n\n\nTidy version\nIn the tidy version, religion and income become variables, and the number of observations in each religion x income combination is a frequency column. This is now tidy insofar as each value in the frequency column represents a unique combination of the religion and income factors, which are coded as variables.\n\n\n\n\n\nreligion\nincome\nfreq\n\n\n\n\nAgnostic\n$10-20k\n34\n\n\nAgnostic\n$100-150k\n109\n\n\nAgnostic\n$20-30k\n60\n\n\nAgnostic\n$30-40k\n81\n\n\nAgnostic\n$40-50k\n76\n\n\nAgnostic\n$50-75k\n137\n\n\nAgnostic\n$75-100k\n122\n\n\nAgnostic\n&lt;$10k\n27\n\n\nAgnostic\n&gt;150k\n84\n\n\nAgnostic\nDon't know/refused\n96\n\n\n\n\n\n\n\nTidying solution\nTo achieve the above transformation, we want to pivot_longer the many columns of income into a single income column.\ntidy1 &lt;- mess1 %&gt;% pivot_longer(cols=-religion, names_to=\"income\", values_to=\"freq\")\nHere, we tell tidyr that we wish to create a lookup (‘key’) column called income whose correponding values will be called freq (here, representing the frequency of this religion x income combination). Furthermore, as additional arguments to pivot_longer, we provide the columns (cols argument) that should be combined, representing levels of the key variable. By specifying -religion, we are saying ‘all columns except religion.’ The alternative would be to provide a comma-separate list of columns like this mess1 %&gt;% pivot_longer(names_to=\"income\", values_to=\"freq\", cols=c(\"&lt;$10k\", \"$10-20k\", etc.))"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#pivot_wider-example",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#pivot_wider-example",
    "title": "Tidy data overview",
    "section": "pivot_wider example",
    "text": "pivot_wider example\nIn our second mess, we have a weather dataset from the Global Historical Climatology Network for one weather station (MX17004) in Mexico. The data represent minimum and maximum temperatures measured across 31 days for five months. The days within each month are on the columns, the months are encoded as a variable month, and the min and max temperatures are separated by row, as identified by the element variable.\n\nMessy version\n\n\nCode\n#show a subset of columns that fit on the page\nmess2 %&gt;% dplyr::select(id:d13) %&gt;% kable_table(n=8)\n\n\n\n\n\nid\nyear\nmonth\nelement\nd1\nd2\nd3\nd4\nd5\nd6\nd7\nd8\nd9\nd10\nd11\nd12\nd13\n\n\n\n\nMX17004\n2010\n1\ntmax\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nMX17004\n2010\n1\ntmin\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nMX17004\n2010\n2\ntmax\nNA\n27.3\n24.1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n29.7\nNA\nNA\n\n\nMX17004\n2010\n2\ntmin\nNA\n14.4\n14.4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n13.4\nNA\nNA\n\n\nMX17004\n2010\n3\ntmax\nNA\nNA\nNA\nNA\n32.1\nNA\nNA\nNA\nNA\n34.5\nNA\nNA\nNA\n\n\nMX17004\n2010\n3\ntmin\nNA\nNA\nNA\nNA\n14.2\nNA\nNA\nNA\nNA\n16.8\nNA\nNA\nNA\n\n\nMX17004\n2010\n4\ntmax\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nMX17004\n2010\n4\ntmin\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\nTidy version\n\n\n\n\n\nid\nyear\nmonth\nday\ntmax\ntmin\n\n\n\n\nMX17004\n2010\n1\n30\n27.8\n14.5\n\n\nMX17004\n2010\n2\n2\n27.3\n14.4\n\n\nMX17004\n2010\n2\n3\n24.1\n14.4\n\n\nMX17004\n2010\n2\n11\n29.7\n13.4\n\n\nMX17004\n2010\n2\n23\n29.9\n10.7\n\n\nMX17004\n2010\n3\n5\n32.1\n14.2\n\n\nMX17004\n2010\n3\n10\n34.5\n16.8\n\n\nMX17004\n2010\n3\n16\n31.1\n17.6\n\n\n\n\n\n\n\nTidying solution\nTo clean this up, we need to bring all of the day columns together using pivot_longer so that we can encode day as a variable and temperature as a variable.\nWe also may want to have max and min temperature as separate columns (i.e., variables), rather than keeping that as a key-value pair. That is, the tmin and tmax values denote the attributes of a single observation, which would usually be represented as separate variables in tidy format. To obtain min and max temperatures as separate columns, we use pivot_wider to move the element values onto separate columns.\nHere is the basic approach:\n#use num_range() to select variables called d1--d31\ntidy2 &lt;- mess2 %&gt;% \n  pivot_longer(\n    cols = num_range(\"d\", 1:31), \n    names_to = \"day\", \n    values_to = \"temperature\",\n    names_prefix = \"d\", #trim off the 'd'\n    names_transform = list(day = as.integer)\n  ) %&gt;%\n  pivot_wider(names_from = \"element\", values_from = \"temperature\") %&gt;%\n  na.omit()\nNotice that pivot_longer has a few built-in arguments for helping us trim off parts of the column names that are not data per se. Here, we have d1–d31, but only the numeric part of that is data. The names_prefix=\"d\" tells pivot_longer to trim the leading ‘d’ from every value in the day column. The names_transform=list(day=as.integer) argument then converts the resulting day values to integers so they behave like a numeric variable rather than text.\nHere, pivot_wider a key – element – that has values 'tmin' or 'tmax' and puts the values of these rows onto columns. This is a kind of ‘long-to-wide’ conversion and we would expect here for the number of rows in the dataset drop two-fold with the pivot_wider compared to the preceding step where we’ve gathered the day columns.\nIt is often useful to check the number of rows after each step in a data transformation pipeline. Here, I just break up the pipeline into the pivot_longer and pivot_wider steps and check the structure in between.\n\n\nCode\ntidy2.1 &lt;- mess2 %&gt;% \n  pivot_longer(\n    cols = num_range(\"d\", 1:31), names_to = \"day\", values_to = \"temperature\",\n    names_prefix = \"d\", names_transform = list(day = as.integer)\n  )\n\nnrow(tidy2.1)\n\n\n[1] 682\n\n\nCode\ntidy2.2 &lt;- tidy2.1 %&gt;%\n  pivot_wider(names_from = \"element\", values_from = \"temperature\")\n\n# with NAs included (since data are sparse), we get the expected 50% reduction in rows\nnrow(tidy2.2)\n\n\n[1] 341\n\n\nCode\n# there are only 33 useful/present observations\nnrow(tidy2.2 %&gt;% na.omit)\n\n\n[1] 33"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#missingness-implicit-vs-explicit",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#missingness-implicit-vs-explicit",
    "title": "Tidy data overview",
    "section": "Missingness: implicit vs explicit",
    "text": "Missingness: implicit vs explicit\nTidy data often needs missing values made explicit (or dropped) so analyses behave as intended.\n\n\nCode\ntidy_missing &lt;- tibble::tribble(\n  ~id, ~day, ~score,\n  1, \"Mon\", 10,\n  1, \"Wed\", 8,\n  2, \"Mon\", 9,\n  3, \"Mon\", NA_real_\n)\n\n# Drop rows where all pivoted values are NA\ntidy_missing %&gt;%\n  tidyr::pivot_wider(names_from = \"day\", values_from = \"score\") %&gt;%\n  dplyr::filter(!dplyr::if_all(-id, is.na))\n\n\n\n\n\n\nid\nMon\nWed\n\n\n\n\n1\n10\n8\n\n\n2\n9\nNA\n\n\n\n\n\n\nCode\n# Make implicit missing combinations explicit\ntidy_missing %&gt;%\n  tidyr::complete(id, day)\n\n\n\n\n\n\nid\nday\nscore\n\n\n\n\n1\nMon\n10\n\n\n1\nWed\n8\n\n\n2\nMon\n9\n\n\n2\nWed\nNA\n\n\n3\nMon\nNA\n\n\n3\nWed\nNA\n\n\n\n\n\n\nCode\n# Fill down within a group (e.g., carry forward metadata). Grouping ensures we\n# only fill within each id; ungroup to avoid carrying this into later steps.\ntidy_missing %&gt;%\n  tidyr::complete(id, day) %&gt;%\n  dplyr::group_by(id) %&gt;%\n  tidyr::fill(score, .direction = \"down\") %&gt;%\n  dplyr::ungroup()\n\n\n\n\n\n\nid\nday\nscore\n\n\n\n\n1\nMon\n10\n\n\n1\nWed\n8\n\n\n2\nMon\n9\n\n\n2\nWed\n9\n\n\n3\nMon\nNA\n\n\n3\nWed\nNA"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#separate-example",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#separate-example",
    "title": "Tidy data overview",
    "section": "separate example",
    "text": "separate example\nIn our third mess, we have multiple variables stored in one column. More specifically, in these data, the ‘m014’ etc. columns represent a combination of sex (m/f) and age range (e.g., 014 is 0–14). The country and year columns are ‘tidy’ because they represent variables, but the sex + age columns are not.\n\nMessy version\n\n\nCode\n#use select to select a few columns that can fit on the page\nmess3 %&gt;% dplyr::select(country:f1524) %&gt;% kable_table(n=5)\n\n\n\n\n\ncountry\nyear\nm014\nm1524\nm2534\nm3544\nm4554\nm5564\nm65\nmu\nf014\nf1524\n\n\n\n\nAD\n2000\n0\n0\n1\n0\n0\n0\n0\nNA\nNA\nNA\n\n\nAE\n2000\n2\n4\n4\n6\n5\n12\n10\nNA\n3\n16\n\n\nAF\n2000\n52\n228\n183\n149\n129\n94\n80\nNA\n93\n414\n\n\nAG\n2000\n0\n0\n0\n0\n0\n0\n1\nNA\n1\n1\n\n\nAL\n2000\n2\n19\n21\n14\n24\n19\n16\nNA\n3\n11\n\n\n\n\n\n\n\nTidy version\n\n\n\n\n\ncountry\nyear\nsex\nage_range\nfreq\n\n\n\n\nAD\n2000\nm\n0-14\n0\n\n\nAE\n2000\nm\n0-14\n2\n\n\nAF\n2000\nm\n0-14\n52\n\n\nAG\n2000\nm\n0-14\n0\n\n\nAL\n2000\nm\n0-14\n2\n\n\nAM\n2000\nm\n0-14\n2\n\n\nAN\n2000\nm\n0-14\n0\n\n\nAO\n2000\nm\n0-14\n186\n\n\n\n\n\n\n\nTidying solution\nWe essentially need to parse apart the ‘m’ from the ‘014’ components of each value, which is a job for separate. Note that we also need to pivot_longer the wacky sex + age columns first to make this easier. Here I use cols=c(-country, -year) to say, ‘all columns except these.’\nThe sep argument of separate tells R how to split the values into multiple variables. Here, by using the number 1, we ask for the first character to become sex and the rest to become age_range.\n\n\nCode\ntidy3 &lt;- mess3 %&gt;% \n  pivot_longer(names_to=\"sex_age\", values_to=\"freq\", cols=c(-country, -year)) %&gt;%\n  separate(sex_age, into=c(\"sex\", \"age_range\"), sep=1)\n\n\nHere, we gathered all columns except country and year into a single key-value pair using pivot_longer. This is an intermediate stage of the dataset that is semi-tidy. We then separate the sex and age components of the values into different variables, resulting in a tidy dataset.\n\n\n\n\n\ncountry\nyear\nsex\nage_range\nfreq\n\n\n\n\nAD\n2000\nm\n014\n0\n\n\nAD\n2000\nm\n1524\n0\n\n\nAD\n2000\nm\n2534\n1\n\n\nAD\n2000\nm\n3544\n0\n\n\nAD\n2000\nm\n4554\n0\n\n\nAD\n2000\nm\n5564\n0\n\n\nAD\n2000\nm\n65\n0\n\n\nAD\n2000\nm\nu\nNA\n\n\n\n\n\nThis is pretty close. The age_range variable is still a little clunky because it isn’t easy to read. We could modify this further using mutate and recode from dplyr, but that’s not the immediate emphasis here.\n\n\nCode\ntidy3 &lt;- tidy3 %&gt;% mutate(age_range=recode(age_range,\n                                           \"014\"=\"0-14\",\n                                           \"1524\"=\"15-24\",\n                                           \"2534\"=\"25-34\",\n                                           \"3544\"=\"35-44\",\n                                           \"4554\"=\"45-54\",\n                                           \"5564\"=\"55-64\",\n                                           \"65\"=\"65+\",\n                                           \"u\"=\"unknown\", .default=NA_character_\n))\n\n\n\n\nModern separate_* alternatives\nFor simple string splitting, tidyr now provides separate_wider_delim() (split on a delimiter) and separate_wider_regex() (split using a regex). These are often clearer than separate() because they create named columns directly.\n\n\nCode\ntoy_people &lt;- tibble::tibble(\n  person = c(\"Ada-Lovelace\", \"Grace-Hopper\", \"Katherine-Johnson\")\n)\n\ntoy_people %&gt;% separate_wider_delim(person, delim = \"-\", names = c(\"first\", \"last\"))\n\n\n\n\n\n\nfirst\nlast\n\n\n\n\nAda\nLovelace\n\n\nGrace\nHopper\n\n\nKatherine\nJohnson\n\n\n\n\n\n\nCode\ntoy_people %&gt;% separate_wider_regex(person, patterns = c(first = \"^[^-]+\", \"-\",\n                                                         last = \"[^-]+$\"\n))\n\n\n\n\n\n\nfirst\nlast\n\n\n\n\nAda\nLovelace\n\n\nGrace\nHopper\n\n\nKatherine\nJohnson\n\n\n\n\n\n\n\n\nTidying solution using pivot_longer alone\nI am ambivalent about whether it is useful to combine separable objectives into a single data wrangling verb. Nevertheless, I want to note that the pivot_longer function provides added functionality for both combining columns into a key-value pair format and splitting the key into multiple variables if the key variable is an amalgamation of discrete variables. This can allow us to skip the separate step:\n\n\nCode\ntidy3 &lt;- mess3 %&gt;% \n  pivot_longer(\n    cols = c(-country, -year), \n    names_to = c(\"sex\", \"age_range\"),\n    names_pattern = \"(.)(.*)\", #first character versus the rest\n    values_to = \"freq\",\n    names_ptypes = list(\n      age_range=factor(\n        levels=c(\"u\", \"014\", \"1524\", \"2534\", \"3544\", \"4554\", \"5564\", \"65\"),\n        ordered=TRUE\n      )\n    )\n  )\n\n#Note: we can't adjust the labels in the names_ptype above using labels=c(...).\n#Thus, we'd need to use recode_factor, similar to the above\ntidy3 &lt;- tidy3 %&gt;% mutate(\n  age_range=recode_factor(age_range,\n                          \"014\"=\"0-14\",\n                          \"1524\"=\"15-24\",\n                          \"2534\"=\"25-34\",\n                          \"3544\"=\"35-44\",\n                          \"4554\"=\"45-54\",\n                          \"5564\"=\"55-64\",\n                          \"65\"=\"65+\",\n                          \"u\"=\"unknown\", .default=NA_character_\n  ))\n\ntidy3 %&gt;% kable_table(n=8)\n\n\n\n\n\ncountry\nyear\nsex\nage_range\nfreq\n\n\n\n\nAD\n2000\nm\n0-14\n0\n\n\nAD\n2000\nm\n15-24\n0\n\n\nAD\n2000\nm\n25-34\n1\n\n\nAD\n2000\nm\n35-44\n0\n\n\nAD\n2000\nm\n45-54\n0\n\n\nAD\n2000\nm\n55-64\n0\n\n\nAD\n2000\nm\n65+\n0\n\n\nAD\n2000\nm\nunknown\nNA"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#unite-example",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#unite-example",
    "title": "Tidy data overview",
    "section": "unite example",
    "text": "unite example\nAlthough the least common of the tidying verbs (in my experience), unite is the complement to separate and can be used to bring together multiple variables that we wish to store as a single variable. For example, we may have first name and last name stored in separate variables, but wish to put them together for display or exporting purposes. Sometimes, we also use unite as an intermediate stage in tidying, bringing together variables, reshaping the data, then re-separating them.\n\n\n\n\n\nfirst_name\nlast_name\nage\nfavorite_color\n\n\n\n\nGraham\nDoe\n11\nPurple\n\n\nKieran\nHelali\n9\nBlue\n\n\nCharlotte\nStafford\n11\nPink\n\n\n\n\n\n\nTidying solution\nIf we wanted to have a full_name, we could use unite to combine first_name and last_name and then get rid of those individual columns.\n\n\nCode\ndf4_united &lt;- df4 %&gt;% unite(col = \"full_name\", first_name, last_name, sep=\" \")\n\n\n\n\n\n\n\nfull_name\nage\nfavorite_color\n\n\n\n\nGraham Doe\n11\nPurple\n\n\nKieran Helali\n9\nBlue\n\n\nCharlotte Stafford\n11\nPink"
  },
  {
    "objectID": "materials/w01_tidy_management/tidy_data_conceptual.html#data.table-meltdcast",
    "href": "materials/w01_tidy_management/tidy_data_conceptual.html#data.table-meltdcast",
    "title": "Tidy data overview",
    "section": "data.table melt/dcast",
    "text": "data.table melt/dcast\nThe data.table package provides melt() and dcast() for fast reshaping. The formula interface is compact for multi-way summary tables, and dcast() can aggregate on the fly while casting.\n\n\nCode\ndt &lt;- data.table::data.table(\n  id = 1:4,\n  group = c(\"A\", \"A\", \"B\", \"B\"),\n  y2022 = c(10, 12, 9, 11),\n  y2023 = c(13, 14, 10, 12),\n  z2022 = c(100, 120, 90, 110),\n  z2023 = c(130, 140, 95, 115)\n)\n\nlong_dt &lt;- data.table::melt(\n  dt,\n  id.vars = c(\"id\", \"group\"),\n  measure.vars = patterns(\"^y\", \"^z\"),\n  variable.name = \"year\",\n  value.name = c(\"y\", \"z\")\n)\n\n# Map pattern indices to actual year labels.\nlong_dt$year &lt;- c(\"2022\", \"2023\")[as.integer(long_dt$year)]\nlong_dt\n\n\n\n\n\n\nid\ngroup\nyear\ny\nz\n\n\n\n\n1\nA\n2022\n10\n100\n\n\n2\nA\n2022\n12\n120\n\n\n3\nB\n2022\n9\n90\n\n\n4\nB\n2022\n11\n110\n\n\n1\nA\n2023\n13\n130\n\n\n2\nA\n2023\n14\n140\n\n\n3\nB\n2023\n10\n95\n\n\n4\nB\n2023\n12\n115\n\n\n\n\n\n\nCode\nmean_y &lt;- data.table::dcast(\n  long_dt,\n  group ~ year,\n  value.var = \"y\",\n  fun.aggregate = mean\n)\n\nmean_y\n\n\n\n\n\n\ngroup\n2022\n2023\n\n\n\n\nA\n11\n13.5\n\n\nB\n10\n11.0\n\n\n\n\n\n\nCode\nmean_multi &lt;- data.table::dcast(\n  long_dt,\n  group ~ year,\n  value.var = c(\"y\", \"z\"),\n  fun.aggregate = mean\n)\n\nmean_multi\n\n\n\n\n\n\ngroup\ny_2022\ny_2023\nz_2022\nz_2023\n\n\n\n\nA\n11\n13.5\n110\n135\n\n\nB\n10\n11.0\n100\n105\n\n\n\n\n\n\nCompared with tidyr, data.table::dcast() makes aggregation part of the casting step and can cast multiple value columns in one pass. It is also a common choice for very large tables where performance matters.\nFurther reshaping extensions using data.table package: https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSYC 859",
    "section": "",
    "text": "Welcome to PSYC 859, Data Management and Visualization, taught at UNC by Michael Hallquist. This website provides access to lectures, labs, and other course materials for the Spring 2026 session.\nUse the Syllabus and Materials tabs to navigate the course schedule and resources.\n\nCourse description\nThis graduate course is intended to provide an applied introduction to data management and data visualization in the social sciences. In order to take full advantage of modern statistical methods (e.g., structural equation models), competency in data management, semi-automated processing, and data wrangling is prerequisite. Likewise, prior to employing inferential statistics, exploratory visualization and analysis is essential to facilitate data cleaning and to form an initial understanding of patterns in the data. This course will cover both the principles and practice of data management, visualization, and exploratory analysis for summarizing quantitative data. In addition, students will learn data science skills to manage and visualize “big data,” where the size or complexity of the dataset defies traditional techniques.\nApplications of data management, visualization, and analysis will use the R statistical programming language. R is quickly becoming the lingua franca in data science across disciplines and offers unparalleled tools for data analysis and visualization.\n\n\nSchedule overview\n\n1/8 (Week 1): Introduction to data management and tidy data\n1/15 (Week 2): Data aggregation, manipulation, joins\n1/22 (Week 3): Data processing and quality assurance, custom functions, basics of automation\n1/29 (Week 4): Advanced data manipulation and management, tracking work in R markdown\n2/5 (Week 5): Principles of data visualization and graphical grammar\n2/12 (Week 6): Visual and graphical perception\n2/19 (Week 7): Graphic design, layout, style, use of color\n2/26 (Week 8): A tour of quantitative visualization\n3/5 (Week 9): Visualizing continuous data (in ggplot2)\n3/12 (Week 10): Visualizing count and categorical data (in ggplot2)\n3/19: No class (Spring break)\n3/26 (Week 11): Maximizing clarity: preparing graphics for presentation and publication\n4/2: No class (Well-being day)\n4/9 (Week 12): Visualizing and understanding fit (and misfit) of statistical models\n4/16 (Week 13): Exploratory statistics for understanding data: clustering, multidimensional scaling, dimension reduction\n4/23 (Week 14): Final presentations of data projects\n\n\n\nObtaining course materials\nTo obtain the full materials for this class, use git clone to download the course repository:\ngit clone https://github.com/michaelhallquist/dataviz_spr2026.git\nIf you already cloned a local copy of the repo, you can get the latest updates using git pull. If all of this git stuff is foreign, I would recommend a quick skim of this documentation: https://happygitwithr.com."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Week 1: Data Tidying (due 1/21 at 8am) — Download QMD\nWeek 2: Workflowr Project Setup (due 1/28 at 8am) — Download QMD"
  },
  {
    "objectID": "assignments/week1_tidyData.html",
    "href": "assignments/week1_tidyData.html",
    "title": "Week 1: Data Tidying",
    "section": "",
    "text": "This assignment is due by 1/21/2026 at 8am."
  },
  {
    "objectID": "assignments/week1_tidyData.html#instructions",
    "href": "assignments/week1_tidyData.html#instructions",
    "title": "Week 1: Data Tidying",
    "section": "Instructions",
    "text": "Instructions\nFor each question either write the code you would use or copy and paste it from the RStudio syntax window. Additionally, paste any (reasonable) output generated by the code. If there is a lot of output, paste enough to see that you were able to get the correct answer."
  },
  {
    "objectID": "assignments/week1_tidyData.html#datasets-for-vignettes",
    "href": "assignments/week1_tidyData.html#datasets-for-vignettes",
    "title": "Week 1: Data Tidying",
    "section": "Datasets for Vignettes",
    "text": "Datasets for Vignettes\nLoad the who2 dataset from the tidyr package into your working environment.\n\n\nCode\ndata(\"who2\", package = \"tidyr\")\n\n\nThis dataset records counts of tuberculosis by country and year. The other values correspond to a method of diagnosis, sex, and age group. The method of diagnosis codes are: rel = relapse, sn = negative pulmonary smear, sp = positive pulmonary smear, ep = extrapulmonary. For example, sp_m_014 corresponds to positive pulmonary smear (sp), male sex (m), and ages 0-14 (014).\nYou will see many NA values in who2 because some country-year combinations do not report counts for certain diagnosis/sex/age groups. When you summarize totals, remember to use na.rm = TRUE so missing values do not turn your results into NA.\nAdditionally, load the Pew relig_income dataset from the tidyr package:\n\n\nCode\ndata(\"relig_income\", package = \"tidyr\")\n\n\nThis dataset describes the relationship between income and religion."
  },
  {
    "objectID": "assignments/week1_tidyData.html#basic-pew-dataset-structure",
    "href": "assignments/week1_tidyData.html#basic-pew-dataset-structure",
    "title": "Week 1: Data Tidying",
    "section": "Basic Pew Dataset Structure",
    "text": "Basic Pew Dataset Structure\nUsing the Pew dataset\n\nLook at the first and last five observations of the Pew dataset using head() and tail(). Is the dataset considered tidy? Why or why not?\n\n\nLook at the structure (str()) and class (class()) of the data. If this is not tidy, verbally describe how it would look if it were a tidy dataset. If it is tidy, is it in a format that you would store the data in long-term?"
  },
  {
    "objectID": "assignments/week1_tidyData.html#tidying-pew-data",
    "href": "assignments/week1_tidyData.html#tidying-pew-data",
    "title": "Week 1: Data Tidying",
    "section": "Tidying Pew Data",
    "text": "Tidying Pew Data\n\nUse tidyr verbs to tidy the Pew dataset. Your tidy dataset should have columns named religion, income, and count. Show the first five rows."
  },
  {
    "objectID": "assignments/week1_tidyData.html#tidying-tuberculosis-data",
    "href": "assignments/week1_tidyData.html#tidying-tuberculosis-data",
    "title": "Week 1: Data Tidying",
    "section": "Tidying Tuberculosis Data",
    "text": "Tidying Tuberculosis Data\nUsing the who2 dataset\n\nExplore the who2 dataset using the methods described in the section above.\n\n\nUsing functions from the tidyr package, tidy the who2 dataset so there is a case_group variable and a cases variable. Use those names throughout the rest of the assignment. Show the first five rows of your new dataframe by using head(). Remember, a tidy dataset consists of:\n\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\n\nThe values within the case_group variable are still considered not tidy because they represent three observations in one (case type, sex, and age). Use tidyr verbs to separate this variable into type, sex, and age (hint: the values are separated by _).\n\n\nCheck that each row is a unique observation by counting duplicates of country, year, type, sex, and age. Report whether any combinations appear more than once.\n\n\nRename the values within sex and age to be more descriptive of what they represent (male or female, 0-4, 5-14, etc.). You can use a combination of dplyr::mutate() and dplyr::recode() to recode the values. Use ?recode if you get stuck.\n\n\nTake your new tidy dataframe with the recoded values and variables and demonstrate tidyr::unite() by recombining sex and age into a single variable (e.g., sex_age). This is just to practice unite() before you mess it up again in the next step. Show the first five rows of your new dataframe.\n\n\nGo back to the dataframe you created in question two. Using that tidy dataframe, use tidyr verbs to recreate a ‘messy’ dataframe. It should look exactly the same (or similar) as when you first loaded the who2 dataset into your environment. Show the first five rows of your new dataframe. If the code throws a ‘duplicate identifiers error’ you should use dplyr::distinct() in your pipeline.\n\n\nArrange the dataset to be descending by most cases of tuberculosis to least using dplyr verbs (use your cases variable).\n\n\nSummarize how many cases of tuberculosis there are by sex and age (use your cases variable). Show your output. If you get NA values for everything, remember to remove those empty values somewhere in your pipeline! Hint Look at the default arguments for the functions you use to summarize your data.\n\n\nFinally, summarize the dataset by country and sex, then add a variable that is the relative prevalence by sex in each country."
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "This page contains course materials used during the demonstration and practical exercises.\n\nWeek 1\n\nTidy data conceptual walkthrough (QMD)\n\n\n\nWeek 2\n\nData wrangling in dplyr (QMD)\nJoins tutorial (QMD)\nStrings in R with stringr (QMD)"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html",
    "title": "Data wrangling in dplyr",
    "section": "",
    "text": "The goal of this document is to provide a basic introduction to data wrangling using functions from the so-called ‘tidyverse’ approach. The tidyverse (https://www.tidyverse.org) is a set of data science packages in R that are intended to provide a consistent paradigm for working with data. This approach unifies a previously inchoate landscape of different functions and packages in R that could be daunting to new users.\nAlthough I do not claim that the tidyverse approach is best according to all possible criteria, I believe that it is the best paradigm for working with data in R for social scientists, many of whom do not have a formal background in computer programming.\nHere, I will draw primarily from the tidyr and dplyr packages in R.\nFor an excellent book-length treatment of the tidyverse approach, see R for Data Science (2nd edition) by Hadley Wickham, Mine Cetinkaya-Rundel, and Garrett Grolemund."
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#addressing-namespace-collisions",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#addressing-namespace-collisions",
    "title": "Data wrangling in dplyr",
    "section": "Addressing namespace collisions",
    "text": "Addressing namespace collisions\n\nWatch out for warnings about objects being ‘masked’ when packages are loaded.\nExplicitly specify the package where your desired function lives using the double colon operator. Example: dplyr::summarize.\nTry to load tidyverse packages using library(tidyverse). This handles collisions within the tidyverse!\n\nIn this document, multilevel pulls in MASS, which masks dplyr::select. We load dplyr last in the setup chunk above. If you ever see the wrong select, use the explicit namespace:\n\n\nCode\nselect\n\n\nfunction (.data, ...) \n{\n    UseMethod(\"select\")\n}\n&lt;bytecode: 0x12027ff58&gt;\n&lt;environment: namespace:dplyr&gt;\n\n\nCode\ndplyr::select\n\n\nfunction (.data, ...) \n{\n    UseMethod(\"select\")\n}\n&lt;bytecode: 0x12027ff58&gt;\n&lt;environment: namespace:dplyr&gt;\n\n\nExample of output that portends a namespace collision:\n\n\nCode\nlibrary(Hmisc)\nlibrary(dplyr)\n\n\nIf you’re unsure which version of a package is being used by R, type the function name without parentheses in the console:\n\n\nCode\nsummarize\n\n\nfunction (.data, ..., .by = NULL, .groups = NULL) \n{\n    by &lt;- enquo(.by)\n    if (!quo_is_null(by) && !is.null(.groups)) {\n        abort(\"Can't supply both `.by` and `.groups`.\")\n    }\n    UseMethod(\"summarise\")\n}\n&lt;bytecode: 0x123e2b420&gt;\n&lt;environment: namespace:dplyr&gt;\n\n\nNotice the part at the bottom: &lt;environment: namespace:dplyr&gt;. This means that the dplyr version of summarize is the one being found by R."
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#use-of-this-reference-in-tidyverse",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#use-of-this-reference-in-tidyverse",
    "title": "Data wrangling in dplyr",
    "section": "Use of ‘this’ reference in tidyverse",
    "text": "Use of ‘this’ reference in tidyverse\nSometimes it is useful to refer to the current dataset or variable explicitly in tidyverse data wrangling syntax.\ndplyr/magrittr tends to hide this from us for convenience, but it’s there under the hood.\niris %&gt;% filter(Sepal.Length &gt; 7)\nis the same as\niris %&gt;% filter(., Sepal.Length &gt; 7)\nSo, '.' refers to the current dataset or variable (depending on context) in dplyr operations. And if you don’t specify where the '.' falls in your syntax, it will always be passed as the first argument to the downstream function."
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#rows-columns-and-groups",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#rows-columns-and-groups",
    "title": "Data wrangling in dplyr",
    "section": "Rows, columns, and groups",
    "text": "Rows, columns, and groups\nMost dplyr workflows can be organized around three kinds of operations: selecting rows, selecting columns, and operating within groups.\n\n\nCode\ndemo_q &lt;- nhanes('DEMO_D')\nbmx_q &lt;- nhanes('BMX_D')\n\n\nNHANES variables used below (from DEMO_D and BMX_D):\n\nSEQN: respondent ID\nRIAGENDR: gender (coded numeric in raw NHANES)\nRIDAGEYR: age in years\nDMDHREDU: education level\nBMXWT: weight (kg)\nBMXARML: upper arm length (cm)\nBMXTHICR: thigh circumference (cm)\n\nRows: keep or reorder observations\n\n\nCode\ndemo_q %&gt;%\n  filter(RIDAGEYR &gt; 25, RIAGENDR == \"Male\") %&gt;%  # filter rows by logical conditions\n  arrange(desc(RIDAGEYR)) %&gt;%                # order rows\n  distinct(DMDHREDU, .keep_all = TRUE) %&gt;%   # keep first row per education level\n  select(SEQN, RIDAGEYR, RIAGENDR, DMDHREDU) %&gt;%\n  kable_table()\n\n\n\n\n\nSEQN\nRIDAGEYR\nRIAGENDR\nDMDHREDU\n\n\n\n\n31447\n85\nMale\nHigh School Grad/GED or equivalent\n\n\n31558\n85\nMale\n9-11th Grade (Includes 12th grade with no diploma)\n\n\n31610\n85\nMale\nSome College or AA degree\n\n\n32444\n85\nMale\nLess Than 9th Grade\n\n\n32455\n85\nMale\nCollege Graduate or above\n\n\n35818\n85\nMale\nNA\n\n\n39906\n78\nMale\nRefused\n\n\n31634\n67\nMale\nDon't know\n\n\n\n\n\nRow filters can also use if_any() and if_all() across multiple columns:\n\n\nCode\nbmx_q %&gt;%\n  filter(if_any(c(BMXWT, BMXARML, BMXTHICR), ~ .x &gt; 60)) %&gt;%  # any column above 60\n  slice_sample(n = 10) %&gt;% # get a random sample of 10 rows\n  kable_table()\n\n\n\n\n\nSEQN\nBMDSTATS\nBMXWT\nBMIWT\nBMXRECUM\nBMIRECUM\nBMXHEAD\nBMIHEAD\nBMXHT\nBMIHT\nBMXBMI\nBMXLEG\nBMILEG\nBMXCALF\nBMICALF\nBMXARML\nBMIARML\nBMXARMC\nBMIARMC\nBMXWAIST\nBMIWAIST\nBMXTHICR\nBMITHICR\nBMXTRI\nBMITRI\nBMXSUB\nBMISUB\n\n\n\n\n38446\nOther partial exam\n76\nNA\nNA\nNA\nNA\nNA\n157\nNA\n31\n35\nNA\n36\nNA\n38\nNA\n34\nNA\n105\nNA\n48\nNA\n27.8\nNA\nNA\nCould not obtain\n\n\n40169\nComplete data for age group\n80\nNA\nNA\nNA\nNA\nNA\n171\nNA\n27\n44\nNA\n40\nNA\n39\nNA\n36\nNA\n92\nNA\n56\nNA\n20.0\nNA\n21\nNA\n\n\n39707\nOther partial exam\nNA\nCould not obtain\nNA\nNA\nNA\nNA\n165\nNA\nNA\n40\nNA\n53\nNA\n39\nNA\n42\nNA\n112\nNA\n73\nNA\n36.0\nNA\nNA\nCould not obtain\n\n\n37066\nComplete data for age group\n78\nNA\nNA\nNA\nNA\nNA\n171\nNot straight\n27\n42\nNA\n38\nNA\n40\nNA\n31\nNA\n98\nNA\n49\nNA\n8.4\nNA\n17\nNA\n\n\n40660\nComplete data for age group\n70\nNA\nNA\nNA\nNA\nNA\n169\nNA\n24\n44\nNA\n35\nNA\n38\nNA\n30\nNA\n93\nNA\n46\nNA\n7.6\nNA\n12\nNA\n\n\n32606\nComplete data for age group\n71\nNA\nNA\nNA\nNA\nNA\n165\nNA\n26\n42\nNA\n37\nNA\n37\nNA\n31\nNA\n92\nNA\n52\nNA\n23.2\nNA\n19\nNA\n\n\n34627\nComplete data for age group\n92\nNA\nNA\nNA\nNA\nNA\n178\nNA\n29\n44\nNA\n45\nNA\n40\nNA\n35\nNA\n103\nNA\n54\nNA\n22.3\nNA\n27\nNA\n\n\n39356\nComplete data for age group\n77\nNA\nNA\nNA\nNA\nNA\n173\nNA\n26\n41\nNA\n38\nNA\n39\nNA\n32\nNA\n86\nNA\n53\nNA\n7.6\nNA\n16\nNA\n\n\n33265\nComplete data for age group\n73\nNA\nNA\nNA\nNA\nNA\n165\nNot straight\n27\n35\nNA\n34\nNA\n39\nNA\n30\nNA\n100\nNA\n43\nNA\n10.6\nNA\n25\nNA\n\n\n39802\nOther partial exam\n100\nNA\nNA\nNA\nNA\nNA\n159\nNA\n40\n30\nNA\n44\nNA\n35\nNA\n36\nNA\n118\nNA\n59\nNA\nNA\nExceeds capacity\n26\nNA\n\n\n\n\n\nCode\nbmx_q %&gt;%\n  filter(if_all(c(BMXWT, BMXARML, BMXTHICR), ~ .x &gt; 30)) %&gt;%  # all columns above 30\n  slice_sample(n = 10) %&gt;%\n  kable_table()\n\n\n\n\n\nSEQN\nBMDSTATS\nBMXWT\nBMIWT\nBMXRECUM\nBMIRECUM\nBMXHEAD\nBMIHEAD\nBMXHT\nBMIHT\nBMXBMI\nBMXLEG\nBMILEG\nBMXCALF\nBMICALF\nBMXARML\nBMIARML\nBMXARMC\nBMIARMC\nBMXWAIST\nBMIWAIST\nBMXTHICR\nBMITHICR\nBMXTRI\nBMITRI\nBMXSUB\nBMISUB\n\n\n\n\n34215\nComplete data for age group\n44\nNA\nNA\nNA\nNA\nNA\n155\nNA\n18\n40\nNA\n34\nNA\n34\nNA\n22\nNA\n62\nNA\n44\nNA\n11.5\nNA\n7.8\nNA\n\n\n35280\nComplete data for age group\n60\nNA\nNA\nNA\nNA\nNA\n168\nNA\n21\n41\nNA\n34\nNA\n37\nNA\n28\nNA\n77\nNA\n47\nNA\n8.8\nNA\n16.0\nNA\n\n\n33135\nComplete data for age group\n61\nNA\nNA\nNA\nNA\nNA\n172\nNA\n20\n42\nNA\n35\nNA\n36\nNA\n27\nNA\n72\nNA\n49\nNA\n17.6\nNA\n11.8\nNA\n\n\n31800\nComplete data for age group\n64\nNA\nNA\nNA\nNA\nNA\n166\nNA\n23\n38\nNA\n34\nNA\n36\nNA\n31\nNA\n88\nNA\n47\nNA\n24.4\nNA\n21.4\nNA\n\n\n40363\nComplete data for age group\n60\nNA\nNA\nNA\nNA\nNA\n170\nNA\n21\n41\nNA\n36\nNA\n36\nNA\n28\nNA\n77\nNA\n48\nNA\n17.0\nNA\n9.2\nNA\n\n\n36612\nComplete data for age group\n51\nNA\nNA\nNA\nNA\nNA\n160\nNA\n20\n36\nNA\n34\nNA\n34\nNA\n24\nNA\n69\nNA\n44\nNA\n19.2\nNA\n14.0\nNA\n\n\n31962\nComplete data for age group\n66\nNA\nNA\nNA\nNA\nNA\n152\nNA\n28\n36\nNA\n35\nNA\n36\nNA\n31\nNA\n93\nNA\n47\nNA\n34.2\nNA\n37.0\nNA\n\n\n34946\nComplete data for age group\n75\nNA\nNA\nNA\nNA\nNA\n171\nNA\n25\n36\nNA\n36\nNA\n36\nNA\n32\nNA\n99\nNA\n50\nNA\n17.5\nNA\n29.4\nNA\n\n\n35053\nComplete data for age group\n73\nNA\nNA\nNA\nNA\nNA\n165\nNA\n27\n39\nNA\n38\nNA\n36\nNA\n28\nNA\n105\nNA\n50\nNA\n18.6\nNA\n12.2\nNA\n\n\n40099\nComplete data for age group\n72\nNA\nNA\nNA\nNA\nNA\n162\nNA\n28\n35\nNA\n36\nNA\n37\nNA\n33\nNA\n98\nNA\n52\nNA\n9.2\nNA\n16.2\nNA\n\n\n\n\n\nNote: filter() drops rows where the condition is NA, so include is.na() checks if you want to keep missing values.\n\n\nCode\nbmx_q %&gt;%\n  filter(is.na(BMXWT) | BMXWT &gt; 60) %&gt;%  # keep missing weights or weights &gt; 60\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nBMDSTATS\nBMXWT\nBMIWT\nBMXRECUM\nBMIRECUM\nBMXHEAD\nBMIHEAD\nBMXHT\nBMIHT\nBMXBMI\nBMXLEG\nBMILEG\nBMXCALF\nBMICALF\nBMXARML\nBMIARML\nBMXARMC\nBMIARMC\nBMXWAIST\nBMIWAIST\nBMXTHICR\nBMITHICR\nBMXTRI\nBMITRI\nBMXSUB\nBMISUB\n\n\n\n\n31129\nComplete data for age group\n75\nNA\nNA\nNA\nNA\nNA\n168\nNA\n27\n43\nNA\n41\nNA\n36\nNA\n33\nNA\n98\nNA\n56\nNA\n19\nNA\n18\nNA\n\n\n31130\nNo body measures exam data\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n31131\nOther partial exam\n75\nNA\nNA\nNA\nNA\nNA\n156\nNA\n31\n38\nNA\n37\nNA\n35\nNA\n36\nNA\n96\nNA\n54\nNA\nNA\nExceeds capacity\nNA\nCould not obtain\n\n\n31132\nComplete data for age group\n70\nNA\nNA\nNA\nNA\nNA\n168\nNA\n25\n40\nNA\n36\nNA\n38\nNA\n31\nNA\n96\nNA\n48\nNA\n10\nNA\n22\nNA\n\n\n31134\nComplete data for age group\n102\nNA\nNA\nNA\nNA\nNA\n182\nNA\n31\n42\nNA\n43\nNA\n43\nNA\n33\nNA\n117\nNA\n50\nNA\n13\nNA\n16\nNA\n\n\n31137\nOther partial exam\n80\nNA\nNA\nNA\nNA\nNA\n170\nNA\n28\n45\nNA\n41\nNA\n38\nNA\n32\nNA\n89\nNA\n60\nNA\n30\nNA\nNA\nCould not obtain\n\n\n\n\n\nYou can also take slices directly:\n\n\nCode\ndemo_q %&gt;%\n  slice_max(RIDAGEYR, n = 3, with_ties = FALSE) %&gt;%  # top 3 rows by age\n  kable_table()\n\n\n\n\n\nSEQN\nSDDSRVYR\nRIDSTATR\nRIDEXMON\nRIAGENDR\nRIDAGEYR\nRIDAGEMN\nRIDAGEEX\nRIDRETH1\nDMQMILIT\nDMDBORN\nDMDCITZN\nDMDYRSUS\nDMDEDUC3\nDMDEDUC2\nDMDSCHOL\nDMDMARTL\nDMDHHSIZ\nDMDFMSIZ\nINDHHINC\nINDFMINC\nINDFMPIR\nRIDEXPRG\nDMDHRGND\nDMDHRAGE\nDMDHRBRN\nDMDHREDU\nDMDHRMAR\nDMDHSEDU\nSIALANG\nSIAPROXY\nSIAINTRP\nFIALANG\nFIAPROXY\nFIAINTRP\nMIALANG\nMIAPROXY\nMIAINTRP\nAIALANG\nWTINT2YR\nWTMEC2YR\nSDMVPSU\nSDMVSTRA\n\n\n\n\n31130\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nFemale\n85\nNA\nNA\nNon-Hispanic White\nNo\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nSome College or AA degree\nNA\nWidowed\n1\n1\n$15,000 to $19,999\n$15,000 to $19,999\n1.99\nNA\nFemale\n85\nBorn in 50 US States or Washington, DC\nSome College or AA degree\nWidowed\nNA\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nNA\nNA\nNA\nNA\n29961\n34031\n2\n46\n\n\n31149\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nFemale\n85\nNA\nNA\nNon-Hispanic White\nNo\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\n9-11th Grade (Includes 12th grade with no diploma)\nNA\nWidowed\n1\n1\n$ 0 to $ 4,999\n$ 0 to $ 4,999\n0.05\nNA\nFemale\n85\nBorn in 50 US States or Washington, DC\n9-11th Grade (Includes 12th grade with no diploma)\nWidowed\nNA\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n23813\n25998\n2\n52\n\n\n31297\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nFemale\n85\nNA\nNA\nNon-Hispanic White\nNo\nBorn Elsewhere\nNot a citizen of the US\n50 years or more\nNA\nHigh School Grad/GED or Equivalent\nNA\nWidowed\n2\n2\n$75,000 and Over\n$75,000 and Over\n5.00\nNA\nMale\n47\nBorn in 50 US States or Washington, DC\nHigh School Grad/GED or equivalent\nDivorced\nNA\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n33863\n36880\n1\n46\n\n\n\n\n\nOr take the first few rows in a group with slice_head():\n\n\nCode\ndemo_q %&gt;%\n  group_by(RIAGENDR) %&gt;%\n  slice_head(n = 2) %&gt;%\n  kable_table()\n\n\n\n\n\nSEQN\nSDDSRVYR\nRIDSTATR\nRIDEXMON\nRIAGENDR\nRIDAGEYR\nRIDAGEMN\nRIDAGEEX\nRIDRETH1\nDMQMILIT\nDMDBORN\nDMDCITZN\nDMDYRSUS\nDMDEDUC3\nDMDEDUC2\nDMDSCHOL\nDMDMARTL\nDMDHHSIZ\nDMDFMSIZ\nINDHHINC\nINDFMINC\nINDFMPIR\nRIDEXPRG\nDMDHRGND\nDMDHRAGE\nDMDHRBRN\nDMDHREDU\nDMDHRMAR\nDMDHSEDU\nSIALANG\nSIAPROXY\nSIAINTRP\nFIALANG\nFIAPROXY\nFIAINTRP\nMIALANG\nMIAPROXY\nMIAINTRP\nAIALANG\nWTINT2YR\nWTMEC2YR\nSDMVPSU\nSDMVSTRA\n\n\n\n\n31127\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nMale\n0\n11\n12\nNon-Hispanic White\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nNA\nNA\nNA\n4\n4\n$15,000 to $19,999\n$15,000 to $19,999\n0.75\nNA\nFemale\n21\nBorn in 50 US States or Washington, DC\nHigh School Grad/GED or equivalent\nMarried\n9-11th Grade (Includes 12th grade with no diploma)\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nNA\nNA\nNA\nNA\n6435\n6571\n2\n44\n\n\n31129\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nMale\n15\n189\n190\nNon-Hispanic Black\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\n10th Grade\nNA\nIn school\nNever married\n6\n6\n$65,000 to $74,999\n$65,000 to $74,999\n2.71\nNA\nMale\n41\nBorn in 50 US States or Washington, DC\nSome College or AA degree\nMarried\nSome College or AA degree\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n5317\n5587\n1\n51\n\n\n31128\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nNovember 1 through April 30\nFemale\n11\n132\n132\nNon-Hispanic Black\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\n4th Grade\nNA\nIn school\nNA\n7\n6\n$45,000 to $54,999\n$20,000 to $24,999\n0.77\nSP not pregnant at exam\nMale\n47\nBorn in 50 US States or Washington, DC\n9-11th Grade (Includes 12th grade with no diploma)\nNA\nNA\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n9082\n8987\n1\n52\n\n\n31130\nNHANES 2005-2006 Public Release\nBoth Interviewed and MEC examined\nMay 1 through October 31\nFemale\n85\nNA\nNA\nNon-Hispanic White\nNo\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nSome College or AA degree\nNA\nWidowed\n1\n1\n$15,000 to $19,999\n$15,000 to $19,999\n1.99\nNA\nFemale\n85\nBorn in 50 US States or Washington, DC\nSome College or AA degree\nWidowed\nNA\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nNA\nNA\nNA\nNA\n29961\n34031\n2\n46\n\n\n\n\n\nColumns: choose or reshape variables\n\n\nCode\ndemo_q %&gt;%\n  select(SEQN, RIAGENDR, RIDAGEYR) %&gt;%    # keep columns\n  rename(gender = RIAGENDR) %&gt;%           # rename columns\n  relocate(RIDAGEYR, .before = gender) %&gt;%    # move columns\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nRIDAGEYR\ngender\n\n\n\n\n31127\n0\nMale\n\n\n31128\n11\nFemale\n\n\n31129\n15\nMale\n\n\n31130\n85\nFemale\n\n\n31131\n44\nFemale\n\n\n31132\n70\nMale\n\n\n\n\n\nTidyselect patterns: select columns by name or type\n\n\nCode\ndemo_q %&gt;%\n  select(SEQN, starts_with(\"RID\"), ends_with(\"YR\")) %&gt;%\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nRIDSTATR\nRIDEXMON\nRIDAGEYR\nRIDAGEMN\nRIDAGEEX\nRIDRETH1\nRIDEXPRG\nSDDSRVYR\nWTINT2YR\nWTMEC2YR\n\n\n\n\n31127\nBoth Interviewed and MEC examined\nMay 1 through October 31\n0\n11\n12\nNon-Hispanic White\nNA\nNHANES 2005-2006 Public Release\n6435\n6571\n\n\n31128\nBoth Interviewed and MEC examined\nNovember 1 through April 30\n11\n132\n132\nNon-Hispanic Black\nSP not pregnant at exam\nNHANES 2005-2006 Public Release\n9082\n8987\n\n\n31129\nBoth Interviewed and MEC examined\nMay 1 through October 31\n15\n189\n190\nNon-Hispanic Black\nNA\nNHANES 2005-2006 Public Release\n5317\n5587\n\n\n31130\nBoth Interviewed and MEC examined\nMay 1 through October 31\n85\nNA\nNA\nNon-Hispanic White\nNA\nNHANES 2005-2006 Public Release\n29961\n34031\n\n\n31131\nBoth Interviewed and MEC examined\nMay 1 through October 31\n44\n535\n536\nNon-Hispanic Black\nSP not pregnant at exam\nNHANES 2005-2006 Public Release\n26458\n26771\n\n\n31132\nBoth Interviewed and MEC examined\nMay 1 through October 31\n70\n842\n843\nNon-Hispanic White\nNA\nNHANES 2005-2006 Public Release\n32962\n35316\n\n\n\n\n\nCode\nbmx_q %&gt;%\n  select(where(is.numeric), matches(\"^BMX\")) %&gt;%\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nBMXWT\nBMXRECUM\nBMXHEAD\nBMIHEAD\nBMXHT\nBMXBMI\nBMXLEG\nBMXCALF\nBMXARML\nBMXARMC\nBMXWAIST\nBMXTHICR\nBMXTRI\nBMXSUB\n\n\n\n\n31127\n10\n74\nNA\nNA\nNA\nNA\nNA\nNA\n16\n16\nNA\nNA\n13\n10.0\n\n\n31128\n40\nNA\nNA\nNA\n152\n17\n38\n29\n34\n22\n63\n40\n10\n8.4\n\n\n31129\n75\nNA\nNA\nNA\n168\n27\n43\n41\n36\n33\n98\n56\n19\n17.6\n\n\n31130\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n31131\n75\nNA\nNA\nNA\n156\n31\n38\n37\n35\n36\n96\n54\nNA\nNA\n\n\n31132\n70\nNA\nNA\nNA\n168\n25\n40\n36\n38\n31\n96\n48\n10\n22.2\n\n\n\n\n\nYou can also drop columns with a leading - inside select():\n\n\nCode\ndemo_q %&gt;%\n  select(-starts_with(\"RID\")) %&gt;%\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nSDDSRVYR\nRIAGENDR\nDMQMILIT\nDMDBORN\nDMDCITZN\nDMDYRSUS\nDMDEDUC3\nDMDEDUC2\nDMDSCHOL\nDMDMARTL\nDMDHHSIZ\nDMDFMSIZ\nINDHHINC\nINDFMINC\nINDFMPIR\nDMDHRGND\nDMDHRAGE\nDMDHRBRN\nDMDHREDU\nDMDHRMAR\nDMDHSEDU\nSIALANG\nSIAPROXY\nSIAINTRP\nFIALANG\nFIAPROXY\nFIAINTRP\nMIALANG\nMIAPROXY\nMIAINTRP\nAIALANG\nWTINT2YR\nWTMEC2YR\nSDMVPSU\nSDMVSTRA\n\n\n\n\n31127\nNHANES 2005-2006 Public Release\nMale\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nNA\nNA\nNA\n4\n4\n$15,000 to $19,999\n$15,000 to $19,999\n0.75\nFemale\n21\nBorn in 50 US States or Washington, DC\nHigh School Grad/GED or equivalent\nMarried\n9-11th Grade (Includes 12th grade with no diploma)\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nNA\nNA\nNA\nNA\n6435\n6571\n2\n44\n\n\n31128\nNHANES 2005-2006 Public Release\nFemale\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\n4th Grade\nNA\nIn school\nNA\n7\n6\n$45,000 to $54,999\n$20,000 to $24,999\n0.77\nMale\n47\nBorn in 50 US States or Washington, DC\n9-11th Grade (Includes 12th grade with no diploma)\nNA\nNA\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n9082\n8987\n1\n52\n\n\n31129\nNHANES 2005-2006 Public Release\nMale\nNA\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\n10th Grade\nNA\nIn school\nNever married\n6\n6\n$65,000 to $74,999\n$65,000 to $74,999\n2.71\nMale\n41\nBorn in 50 US States or Washington, DC\nSome College or AA degree\nMarried\nSome College or AA degree\nEnglish\nYes\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n5317\n5587\n1\n51\n\n\n31130\nNHANES 2005-2006 Public Release\nFemale\nNo\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nSome College or AA degree\nNA\nWidowed\n1\n1\n$15,000 to $19,999\n$15,000 to $19,999\n1.99\nFemale\n85\nBorn in 50 US States or Washington, DC\nSome College or AA degree\nWidowed\nNA\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nNA\nNA\nNA\nNA\n29961\n34031\n2\n46\n\n\n31131\nNHANES 2005-2006 Public Release\nFemale\nNo\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nSome College or AA degree\nNA\nMarried\n4\n4\n$75,000 and Over\n$75,000 and Over\n4.65\nMale\n36\nBorn in 50 US States or Washington, DC\nCollege Graduate or above\nMarried\nSome College or AA degree\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n26458\n26771\n1\n48\n\n\n31132\nNHANES 2005-2006 Public Release\nMale\nYes\nBorn in 50 US States or Washington, DC\nCitizen by birth or naturalization\nNA\nNA\nCollege Graduate or above\nNA\nMarried\n2\n2\n$75,000 and Over\n$75,000 and Over\n5.00\nMale\n70\nBorn in 50 US States or Washington, DC\nCollege Graduate or above\nMarried\nCollege Graduate or above\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\nNo\nNo\nEnglish\n32962\n35316\n2\n52\n\n\n\n\n\nConditional transforms: create variables with if_else() and case_when()\n\n\nCode\ndemo_q %&gt;%\n  mutate(\n    adult = if_else(RIDAGEYR &gt;= 18, \"adult\", \"minor\"),\n    age_group = case_when(\n      RIDAGEYR &lt; 18 ~ \"child\",\n      RIDAGEYR &lt; 65 ~ \"adult\",\n      TRUE ~ \"older adult\"\n    )\n  ) %&gt;%\n  select(SEQN, RIDAGEYR, age_group) %&gt;%\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\nRIDAGEYR\nage_group\n\n\n\n\n31127\n0\nchild\n\n\n31128\n11\nchild\n\n\n31129\n15\nchild\n\n\n31130\n85\nolder adult\n\n\n31131\n44\nadult\n\n\n31132\n70\nolder adult\n\n\n\n\n\nMutate across: apply the same transformation to multiple columns\n\n\nCode\nbmx_q %&gt;%\n  mutate(\n    across(\n      c(BMXWT, BMXARML, BMXTHICR),\n      ~ .x - mean(.x, na.rm = TRUE),\n      .names = \"centered_{.col}\"\n    )\n  ) %&gt;%\n  dplyr::select(SEQN, starts_with(\"centered_\")) %&gt;%\n  kable_table(n = 6)\n\n\n\n\n\nSEQN\ncentered_BMXWT\ncentered_BMXARML\ncentered_BMXTHICR\n\n\n\n\n31127\n-49.8\n-16.7\nNA\n\n\n31128\n-19.9\n1.6\n-11.8\n\n\n31129\n14.6\n3.8\n4.6\n\n\n31130\nNA\nNA\nNA\n\n\n31131\n15.2\n2.3\n2.4\n\n\n31132\n9.5\n4.8\n-3.3\n\n\n\n\n\nGroups: summarize or mutate within groups\ngroup_by() can use multiple keys (e.g., group_by(BTN, COMPANY)) and ungroup() drops grouping when you’re done.\n\n\nCode\ndemo_q %&gt;%\n  group_by(RIAGENDR) %&gt;%\n  summarize(\n    n = n(),\n    avg_age = mean(RIDAGEYR, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  kable_table()\n\n\n\n\n\nRIAGENDR\nn\navg_age\n\n\n\n\nMale\n5080\n28\n\n\nFemale\n5268\n28\n\n\n\n\n\nGrouping persists across verbs until you ungroup() (or use .groups in summarize()):\n\n\nCode\ndemo_q %&gt;%\n  group_by(RIAGENDR) %&gt;%\n  mutate(mean_age = mean(RIDAGEYR, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  summarize(overall_mean = mean(RIDAGEYR, na.rm = TRUE)) %&gt;%\n  kable_table()\n\n\n\n\n\noverall_mean\n\n\n\n\n28\n\n\n\n\n\nQuick counting helpers:\n\n\nCode\ndemo_q %&gt;%\n  count(RIAGENDR)                      # counts per gender\n\n\n\n\n\n\nRIAGENDR\nn\n\n\n\n\nMale\n5080\n\n\nFemale\n5268\n\n\n\n\n\n\nCode\ndemo_q %&gt;%\n  summarize(n_edu = n_distinct(DMDHREDU))\n\n\n\n\n\n\nn_edu\n\n\n\n\n8\n\n\n\n\n\n\nFor single summaries, you can also use .by instead of group_by():\n\n\nCode\ndemo_q %&gt;%\n  summarize(\n    avg_age = mean(RIDAGEYR, na.rm = TRUE),\n    .by = RIAGENDR # compute summary within gender without keeping groups\n  )\n\n\n\n\n\n\nRIAGENDR\navg_age\n\n\n\n\nMale\n28\n\n\nFemale\n28"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#overview-a-first-pass-through-an-nhanes-dataset",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#overview-a-first-pass-through-an-nhanes-dataset",
    "title": "Data wrangling in dplyr",
    "section": "Overview: a first pass through an NHANES dataset",
    "text": "Overview: a first pass through an NHANES dataset\nTo learn dplyr, let’s start with a survey from the National Health and Nutrition Examination Survey (NHANES) dataset. These data are provided in the nhanesA package. We’ll start by looking at a couple of basic demographic variables.\n\n\nCode\n# demographics: note that this code relies on functions in the nhanesA package, which\n#   is useful for working with NHANES data, but is not a focus of this workshop per se.\n\ndemo_d &lt;- nhanes('DEMO_D')\ndemo_d_vars  &lt;- nhanesTableVars('DEMOGRAPHICS', 'DEMO_D', namesonly=TRUE)\n\n# translate numeric codes into factors by using the nhanes lookup/codebook functions\ndemo_d &lt;- suppressWarnings(nhanesTranslate('DEMO_D', demo_d_vars, data=demo_d))\n\n\nTranslated columns: AIALANG DMDBORN DMDCITZN DMDEDUC2 DMDEDUC3 DMDHRBRN DMDHREDU DMDHRGND DMDHRMAR DMDHSEDU DMDMARTL DMDSCHOL DMDYRSUS DMQMILIT FIAINTRP FIALANG FIAPROXY INDFMINC INDHHINC MIAINTRP MIALANG MIAPROXY RIAGENDR RIDEXMON RIDEXPRG RIDRETH1 RIDSTATR SDDSRVYR SIAINTRP SIALANG SIAPROXY\n\n\nCode\n# dplyr pipeline\ndemo_d &lt;- demo_d %&gt;% \n  filter(!INDHHINC %in% c(\"Over $20,000\", \"Under $20,000\", \"Refused\", \"Don't know\")) %&gt;% \n  droplevels() %&gt;% # drop unused factor levels from the data.frame\n  mutate(\n    # case_when() is a vectorized if/else ladder for many conditions\n    income_num = case_when( # convert range-based factor labels to midpoint numbers\n    INDHHINC == \"$     0 to $ 4,999\" ~ 2500,\n    INDHHINC == \"$ 5,000 to $ 9,999\" ~ 7500,\n    INDHHINC == \"$10,000 to $14,999\" ~ 12500,\n    INDHHINC == \"$15,000 to $19,999\" ~ 17500,\n    INDHHINC == \"$20,000 to $24,999\" ~ 22500,\n    INDHHINC == \"$25,000 to $34,999\" ~ 30000,\n    INDHHINC == \"$35,000 to $44,999\" ~ 40000,\n    INDHHINC == \"$45,000 to $54,999\" ~ 50000,\n    INDHHINC == \"$55,000 to $64,999\" ~ 60000,\n    INDHHINC == \"$65,000 to $74,999\" ~ 70000,\n    INDHHINC == \"$75,000 and Over\" ~ 80000\n    )\n  )\n \n#load body (biometric) measures\nbmx_d &lt;- nhanes('BMX_D')\nbmx_d_vars  &lt;- nhanesTableVars('EXAM', 'BMX_D', namesonly=TRUE)\nbmx_d &lt;- suppressWarnings(nhanesTranslate('BMX_D', bmx_d_vars, data=bmx_d))\n\n\nTranslated columns: BMDSTATS BMIARMC BMIARML BMICALF BMIHT BMILEG BMIRECUM BMISUB BMITHICR BMITRI BMIWAIST BMIWT\n\n\nCode\n# merge the education demographics variable with the biometric data, joining on the SEQN column (basically an ID)\nbmx_d &lt;- demo_d %&gt;% \n  dplyr::select(SEQN, DMDHREDU) %&gt;% \n  inner_join(bmx_d, by=\"SEQN\")"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#group_by-summarize",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#group_by-summarize",
    "title": "Data wrangling in dplyr",
    "section": "group_by + summarize",
    "text": "group_by + summarize\nLet’s summarize the mean household income (income_num), converted from categories in INDHHINC) by highest level of education completed (DMDHREDU)\n\n\nCode\ndemo_d %&gt;% \n  group_by(DMDHREDU) %&gt;% # divide dataset into separate compartments by education level\n  dplyr::summarize(\n    n=n(), # number of observations\n    m_income=mean(income_num, na.rm=T), \n    sd_income=sd(income_num, na.rm=T)\n  ) %&gt;% \n  kable_table()\n\n\n\n\n\nDMDHREDU\nn\nm_income\nsd_income\n\n\n\n\nLess Than 9th Grade\n1173\n28024\n18489\n\n\n9-11th Grade (Includes 12th grade with no diploma)\n1626\n31318\n21584\n\n\nHigh School Grad/GED or equivalent\n2317\n39400\n23422\n\n\nSome College or AA degree\n2664\n48137\n25326\n\n\nCollege Graduate or above\n1768\n63785\n21816\n\n\nRefused\n6\n25000\n12624\n\n\nDon't know\n26\n20900\n15760\n\n\nNA\n276\n44623\n24849\n\n\n\n\n\nNote that summarize removes a single level of grouping in the group_by process. Here, we only have one grouping variable, DMDHREDU, so the output of summarize will be ‘ungrouped.’"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#grouped-summaries-of-several-variables",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#grouped-summaries-of-several-variables",
    "title": "Data wrangling in dplyr",
    "section": "Grouped summaries of several variables",
    "text": "Grouped summaries of several variables\nWhat if I want to have means and SDs for several continuous variables grouped by highest education? Let’s look specifically at the weight (BMXWT), upper arm length (BMXARML), and thigh circumference (BMXTHICR) measurements. The combination of summarize and across provide functionality to specify several variables using the .cols argument of across and potentially several summary functions by passing them in a named list.\n\n\nCode\nbmx_d %&gt;% \n  group_by(DMDHREDU) %&gt;% \n  dplyr::summarize(\n    across(\n      c(BMXWT, BMXARML, BMXTHICR), \n      list(m=~mean(.x, na.rm=T), sd=~sd(.x, na.rm=T))\n    )\n  ) %&gt;% \n  kable_table()\n\n\n\n\n\nDMDHREDU\nBMXWT_m\nBMXWT_sd\nBMXARML_m\nBMXARML_sd\nBMXTHICR_m\nBMXTHICR_sd\n\n\n\n\nLess Than 9th Grade\n58\n30\n32\n7.8\n50\n7.48\n\n\n9-11th Grade (Includes 12th grade with no diploma)\n56\n33\n32\n8.2\n51\n8.40\n\n\nHigh School Grad/GED or equivalent\n61\n33\n33\n7.9\n52\n8.10\n\n\nSome College or AA degree\n62\n32\n33\n7.6\n52\n8.65\n\n\nCollege Graduate or above\n61\n31\n33\n7.8\n52\n7.99\n\n\nRefused\n70\n25\n38\n2.5\n50\n0.57\n\n\nDon't know\n50\n36\n28\n11.5\n53\n7.74\n\n\nNA\n56\n29\n32\n7.6\n51\n7.73\n\n\n\n\n\nLet’s slow this down:\n\ngroup_by verb\nsurvey %&gt;% group_by(DMDHREDU)\nThis tells dplyr to divide the bmx_d (NHANES biometric measurements) data into a set of smaller data.frame objects, one per level of DMDHREDU. Internally, this looks something like the output below. After this division of the dataset into chunks, summarize will work on each chunk individually.\n\n\n$`Less Than 9th Grade`\n   SEQN            DMDHREDU                    BMDSTATS BMXWT\n1 31137 Less Than 9th Grade          Other partial exam    80\n2 31157 Less Than 9th Grade Complete data for age group    42\n3 31169 Less Than 9th Grade Complete data for age group    22\n4 31175 Less Than 9th Grade Complete data for age group    86\n\n$`9-11th Grade (Includes 12th grade with no diploma)`\n   SEQN                                           DMDHREDU\n1 31128 9-11th Grade (Includes 12th grade with no diploma)\n2 31133 9-11th Grade (Includes 12th grade with no diploma)\n3 31145 9-11th Grade (Includes 12th grade with no diploma)\n4 31148 9-11th Grade (Includes 12th grade with no diploma)\n                     BMDSTATS BMXWT\n1 Complete data for age group    40\n2 Complete data for age group    45\n3 Complete data for age group    40\n4 Complete data for age group    52\n\n$`High School Grad/GED or equivalent`\n   SEQN                           DMDHREDU                    BMDSTATS BMXWT\n1 31127 High School Grad/GED or equivalent Complete data for age group    10\n2 31139 High School Grad/GED or equivalent          Other partial exam    74\n3 31140 High School Grad/GED or equivalent Complete data for age group    42\n4 31143 High School Grad/GED or equivalent Complete data for age group    76\n\n$`Some College or AA degree`\n   SEQN                  DMDHREDU                    BMDSTATS BMXWT\n1 31129 Some College or AA degree Complete data for age group    75\n2 31130 Some College or AA degree  No body measures exam data    NA\n3 31138 Some College or AA degree Complete data for age group    14\n4 31142 Some College or AA degree          Other partial exam    80\n\n$`College Graduate or above`\n   SEQN                  DMDHREDU                    BMDSTATS BMXWT\n1 31131 College Graduate or above          Other partial exam    75\n2 31132 College Graduate or above Complete data for age group    70\n3 31135 College Graduate or above Complete data for age group    10\n4 31141 College Graduate or above Complete data for age group    60\n\n$Refused\n   SEQN DMDHREDU                             BMDSTATS BMXWT\n1 33385  Refused          Complete data for age group    78\n2 35296  Refused Partial:  Height and weight obtained    38\n3 37761  Refused          Complete data for age group    67\n4 40762  Refused Partial:  Height and weight obtained    99\n\n$`Don't know`\n   SEQN   DMDHREDU                    BMDSTATS BMXWT\n1 31546 Don't know          Other partial exam    78\n2 32106 Don't know Complete data for age group    12\n3 32626 Don't know Complete data for age group    64\n4 32648 Don't know Complete data for age group    85\n\n\n\n\nsummarize + across\nThe summarize function transforms a dataset that has many rows to a dataset that has a single row per grouping unit. If you do not use group_by, summarize will yield an overall summary statistic in the entire dataset. For example, to get the mean and SD of household income in NHANES, irrespective of education level or other categorical moderators, we could just use a simple summarize:\n\n\nCode\ndemo_d %&gt;%\n  dplyr::summarize(\n    m_income=mean(income_num, na.rm=T), \n    sd_income=sd(income_num, na.rm=T)\n  ) %&gt;% \n  kable_table()\n\n\n\n\n\nm_income\nsd_income\n\n\n\n\n43590\n25726\n\n\n\n\n\nBut because we used group_by(DMDHREDU) above, we got unique summaries of the variables at each level of education.\nThe across function accepts two primary arguments. First, we specify a set of variables (the .cols argument) that we wish to summarize in the same way (i.e., compute the same summary statistics). Second, we specify which statistics we wish to compute (the .fns argument). In our case, the syntax was:\ndplyr::summarize(\n    across(c(BMXWT, BMXARML, BMXTHICR), \n           list(m=~mean(.x, na.rm=T), sd=~sd(.x, na.rm=T)))\n)\nThe c() function specifies a vector of unquoted variable names in the dataset we wish to summarize, separated by commas. Note that any tidyselect operator for selecting columns will work. This includes starts_with, ends_with, matches, and others. For details, see ?dplyr_tidy_select.\nThe list() here asks dplyr to run each function in the list against each variables in the .cols specification. Here, this means that dplyr will compute the mean and SD of each variable in the .cols argument at each level of education completed (the group_by basis). The names of the list elements (left side) — here, m and sd — become the suffixes added for each variable. The value of the element (right side) — here, mean and sd — are the functions that should be used to compute a summary statistic (they should return one number per grouped variable).\nNote that the column names that result from an across operation can be modified using the .names argument. The default is to suffix the variable name with the names of the functions list, preceded by an underscore (e.g., income_m).\nPassing arguments to summary functions\nNotice how we passed na.rm=TRUE to the mean function within the list. This tells the mean to ignore missing (NA) values when computing the mean (i.e., mean of the non-missing numbers). In general, the dplyr syntax using what they call “lambdas” (starting with ~) is the clearest way to control the arguments passed to each function. Here is a simple definition of a lambda in R:\n~ mean(.x, na.rm=TRUE)\nThe .x refers to the current variable being used within a dplyr data wrangling operation. This is in contrast to ., which generally refers to the current dataset.\nIf you don’t need to pass arguments to the functions in an across() operation, you can just state the function name:\ndplyr::summarize(\n    across(c(BMXWT, BMXARML, BMXTHICR), \n           list(m=mean, sd=sd))\n)"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#making-a-summarize-pipeline-even-more-beautiful",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#making-a-summarize-pipeline-even-more-beautiful",
    "title": "Data wrangling in dplyr",
    "section": "Making a summarize pipeline even more beautiful",
    "text": "Making a summarize pipeline even more beautiful\nWe can also make the output more beautiful using tidying techniques we’ve already seen in the tidyr tutorial. Remember that R is all about programming for data science. In particular, notice that we have some columns that are means and others that are SDs.\nWe can just extend our data pipeline a bit. The extract function from tidyr here is like separate, but with a bit more oomph using regular expressions. This is a more intermediate topic, but there is a useful tutorial here: http://www.regular-expressions.info/tutorial.html.\n\n\nCode\nbmx_d %&gt;% \n  group_by(DMDHREDU) %&gt;% \n  dplyr::summarize(\n    across(\n      c(BMXWT, BMXARML, BMXTHICR), \n      list(m=~mean(.x, na.rm=T), sd=~sd(.x, na.rm=T))\n    )\n  ) %&gt;%\n  \n   # combine m and sd statistics (notice how you can add comments inline within a pipeline?)\n  pivot_longer(cols=-DMDHREDU, names_to = \"Measure\", values_to = \"value\") %&gt;%\n  \n  # divide income_m into income and m\n  #extract(col=Measure, into=c(\"bio_measure\", \"statistic\"), regex=(\"(.*)_(.*)$\")) %&gt;% \n  separate(col=Measure, into=c(\"bio_measure\", \"statistic\"), sep=\"_\") %&gt;% \n  pivot_wider(names_from=statistic, values_from = value) %&gt;% \n  arrange (bio_measure, DMDHREDU) %&gt;%\n  kable_table()\n\n\n\n\n\nDMDHREDU\nbio_measure\nm\nsd\n\n\n\n\nLess Than 9th Grade\nBMXARML\n32\n7.77\n\n\n9-11th Grade (Includes 12th grade with no diploma)\nBMXARML\n32\n8.22\n\n\nHigh School Grad/GED or equivalent\nBMXARML\n33\n7.86\n\n\nSome College or AA degree\nBMXARML\n33\n7.61\n\n\nCollege Graduate or above\nBMXARML\n33\n7.81\n\n\nRefused\nBMXARML\n38\n2.47\n\n\nDon't know\nBMXARML\n28\n11.49\n\n\nNA\nBMXARML\n32\n7.62\n\n\nLess Than 9th Grade\nBMXTHICR\n50\n7.48\n\n\n9-11th Grade (Includes 12th grade with no diploma)\nBMXTHICR\n51\n8.40\n\n\nHigh School Grad/GED or equivalent\nBMXTHICR\n52\n8.10\n\n\nSome College or AA degree\nBMXTHICR\n52\n8.65\n\n\nCollege Graduate or above\nBMXTHICR\n52\n7.99\n\n\nRefused\nBMXTHICR\n50\n0.57\n\n\nDon't know\nBMXTHICR\n53\n7.74\n\n\nNA\nBMXTHICR\n51\n7.73\n\n\nLess Than 9th Grade\nBMXWT\n58\n30.15\n\n\n9-11th Grade (Includes 12th grade with no diploma)\nBMXWT\n56\n33.44\n\n\nHigh School Grad/GED or equivalent\nBMXWT\n61\n32.70\n\n\nSome College or AA degree\nBMXWT\n62\n32.48\n\n\nCollege Graduate or above\nBMXWT\n61\n31.30\n\n\nRefused\nBMXWT\n70\n25.08\n\n\nDon't know\nBMXWT\n50\n36.00\n\n\nNA\nBMXWT\n56\n29.12\n\n\n\n\n\n\narrange: order observations\nToward the end of the pipeline above, we see:\narrange (bio_measure, DMDHREDU) %&gt;%\nThe arrange verb in dplyr requests that observations be sorted according to one or more variables. Here, we ask for the dataset to be sorted by bio_measure (biometric measure, such as weight) first, then by education level within that measure. The arrange verb sorts observations in ascending order (low to high) by default, but data can be sorted in descending order using the desc() function:\narrange(bio_measure, desc(DMDHREDU)) %&gt;%\nThis would sort by highest to lowest education level within each measure (bio_measure), where the bio_measures are still in ascending (alphabetical) order"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#filter-obtaining-observations-rows-based-on-some-criteria",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#filter-obtaining-observations-rows-based-on-some-criteria",
    "title": "Data wrangling in dplyr",
    "section": "filter: obtaining observations (rows) based on some criteria",
    "text": "filter: obtaining observations (rows) based on some criteria\nObjective: Retain only men in company A\n\n\nCode\nCOMPANY=\"A\"\nCOMPANY &lt;- \"A\"\n\ncompany_A_men &lt;- filter(univbct, COMPANY==\"A\" & GENDER==1)\n#print 10 observations at random to check the accuracy of the filter\n#p=11 just shows the first 11 columns to keep it on one page for formatting\ncompany_A_men %&gt;% sample_n(10) %&gt;% kable_table(p=11)\n\n\n\n\n\n\nBTN\nCOMPANY\nMARITAL\nGENDER\nHOWLONG\nRANK\nEDUCATE\nAGE\nJOBSAT1\nCOMMIT1\nREADY1\n\n\n\n\n456\n3066\nA\n1\n1\n0\n13\n2\n19\n4.0\n4.0\n4.0\n\n\n1445\n404\nA\n1\n1\n2\n14\n2\n25\n2.3\n2.7\n1.2\n\n\n320\n4042\nA\n1\n1\n1\n21\n5\n24\n2.0\n3.7\n4.0\n\n\n103\n299\nA\n5\n1\n2\n13\n2\n19\nNA\nNA\nNA\n\n\n572\n299\nA\n2\n1\n3\n13\n2\n21\n4.7\n4.3\n3.2\n\n\n658\n4\nA\n4\n1\n5\n15\n2\n29\n3.0\n3.0\n3.2\n\n\n539\n1022\nA\n4\n1\n1\n14\n2\n26\nNA\nNA\nNA\n\n\n525\n4042\nA\n1\n1\n5\n22\n5\n25\n3.7\n4.0\n3.2\n\n\n1189\n144\nA\n1\n1\n3\n13\n2\n20\n4.3\n3.3\n2.5\n\n\n899\n4042\nA\n4\n1\n2\n17\n4\n36\n4.0\n4.7\n3.5\n\n\n\n\n\nObjective: Count how many people are in companies A and B\n\n\nCode\nfilter(univbct, COMPANY %in% c(\"A\",\"B\")) %&gt;% nrow()\n\n\n[1] 750\n\n\nObjective: What about counts by company and battalion?\n\n\nCode\nunivbct %&gt;% \n  group_by(BTN, COMPANY) %&gt;% \n  tally() %&gt;%\n  kable_table(n=12)\n\n\n\n\n\nBTN\nCOMPANY\nn\n\n\n\n\n4\nA\n66\n\n\n4\nB\n15\n\n\n4\nC\n12\n\n\n4\nD\n30\n\n\n4\nHHC\n18\n\n\n104\nA\n12\n\n\n104\nHHC\n3\n\n\n124\nA\n42\n\n\n144\nA\n30\n\n\n299\nA\n39\n\n\n299\nB\n30\n\n\n299\nC\n27\n\n\n\n\n\nCode\n# N.B. The same result could be obtained with count(BTN, COMPANY) alone.\n#  This combines the group_by and tally functions"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#select-choose-variables-columns-based-on-some-criteria",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#select-choose-variables-columns-based-on-some-criteria",
    "title": "Data wrangling in dplyr",
    "section": "select: choose variables (columns) based on some criteria",
    "text": "select: choose variables (columns) based on some criteria\nLet’s start by keeping only the three core dependent variables over time: jobsat, commit, ready. Keep SUBNUM as well for unique identification.\n\n\nCode\ndvs_only &lt;- univbct %&gt;% \n  dplyr::select(SUBNUM, JOBSAT1, JOBSAT2, JOBSAT3, \n                COMMIT1, COMMIT2, COMMIT3, \n                READY1, READY2, READY3)\n\n\nIf you have many variables of a similar name, you might try starts_with(). Note in this case that it brings in “READY”, too. Note that you can mix different selection mechanisms within select. Look at the cheatsheet.\n\n\nCode\ndvs_only &lt;- univbct %&gt;% \n  dplyr::select(SUBNUM, starts_with(\"JOBSAT\"), starts_with(\"COMMIT\"), starts_with(\"READY\"))\n\n\nOther selection mechanisms:\n\ncontains: variable name contains a literal string\nstarts_with: variable names start with a string\nends_with: variable names end with a string\nnum_range: variables that have a common prefix (e.g., ‘reasoning’) and a numeric range (e.g., 1-20)\nmatches: variable name matches a regular expression\none_of: variable is one of the elements in a character vector. Example: select(one_of(c(“A”, “B”)))\n\nSee ?select_helpers for more details."
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#select-filter-zooming-in-on-specific-observations-and-variables",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#select-filter-zooming-in-on-specific-observations-and-variables",
    "title": "Data wrangling in dplyr",
    "section": "select + filter: zooming in on specific observations and variables",
    "text": "select + filter: zooming in on specific observations and variables\nNote that select and filter can be combined to subset both observations and variables of interest.\nFor example, look at readiness to deploy in battalion 299 only:\n\n\nCode\nunivbct %&gt;% \n  filter(BTN==299) %&gt;% \n  dplyr::select(SUBNUM, READY1, READY2, READY3) %&gt;% \n  kable_table(n=6)\n\n\n\n\n\n\nSUBNUM\nREADY1\nREADY2\nREADY3\n\n\n\n\n10\n4\n2.5\n3.2\n3.0\n\n\n11\n4\n2.5\n3.2\n3.0\n\n\n12\n4\n2.5\n3.2\n3.0\n\n\n19\n7\n2.0\n1.8\n1.2\n\n\n20\n7\n2.0\n1.8\n1.2\n\n\n21\n7\n2.0\n1.8\n1.2\n\n\n\n\n\nselect is also useful for dropping variables that are not of interest using a kind of subtraction syntax.\n\n\nCode\nnojobsat &lt;- univbct %&gt;% \n  dplyr::select(-starts_with(\"JOBSAT\"))\nnames(nojobsat)\n\n\n [1] \"BTN\"     \"COMPANY\" \"MARITAL\" \"GENDER\"  \"HOWLONG\" \"RANK\"    \"EDUCATE\"\n [8] \"AGE\"     \"COMMIT1\" \"READY1\"  \"COMMIT2\" \"READY2\"  \"COMMIT3\" \"READY3\" \n[15] \"TIME\"    \"JSAT\"    \"COMMIT\"  \"READY\"   \"SUBNUM\""
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#mutate-add-one-or-more-variables-that-are-a-function-of-other-variables",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#mutate-add-one-or-more-variables-that-are-a-function-of-other-variables",
    "title": "Data wrangling in dplyr",
    "section": "mutate: add one or more variables that are a function of other variables",
    "text": "mutate: add one or more variables that are a function of other variables\n(Row-wise) mean of commit scores over waves. Note how you can used select() within a mutate to run a function on a subset of the data.\n\n\nCode\nunivbct &lt;- univbct %&gt;% \n  mutate(commitmean=rowMeans(dplyr::select(., COMMIT1, COMMIT2, COMMIT3)))\n\n\nMutate can manipulate several variables in one call. Here, mean center any variable that starts with COMMIT and add the suffix _cm for clarity. Also compute the percentile rank for each of these columns, with _pct as suffix. Note the use of the starts_with function here within the across(). This operates identically to select, but in the context of a summary or mutation operation on specific variables. See ?select_helpers for details.\n\n\nCode\nmeancent &lt;- function(x) { x - mean(x, na.rm=TRUE) } #simple worker function to mean center a variable\n\nunivbct &lt;- univbct %&gt;% \n  mutate(across(starts_with(\"COMMIT\", ignore.case = FALSE), list(cm=meancent, pct=percent_rank)))\n\nunivbct %&gt;%\n  dplyr::select(starts_with(\"COMMIT\", ignore.case = FALSE)) %&gt;%\n  kable_table(n=8) %&gt;% kable_styling(font_size = 12)\n\n\n\n\n\nCOMMIT1\nCOMMIT2\nCOMMIT3\nCOMMIT\nCOMMIT1_cm\nCOMMIT1_pct\nCOMMIT2_cm\nCOMMIT2_pct\nCOMMIT3_cm\nCOMMIT3_pct\nCOMMIT_cm\nCOMMIT_pct\n\n\n\n\n1.7\n1.7\n3.0\n1.7\n-1.95\n0.01\n-1.80\n0.04\n-0.54\n0.12\n-1.87\n0.02\n\n\n1.7\n1.7\n3.0\n1.7\n-1.95\n0.01\n-1.80\n0.04\n-0.54\n0.12\n-1.87\n0.02\n\n\n1.7\n1.7\n3.0\n3.0\n-1.95\n0.01\n-1.80\n0.04\n-0.54\n0.12\n-0.54\n0.15\n\n\n1.7\n1.3\n1.3\n1.7\n-1.95\n0.01\n-2.13\n0.03\n-2.20\n0.01\n-1.87\n0.02\n\n\n1.7\n1.3\n1.3\n1.3\n-1.95\n0.01\n-2.13\n0.03\n-2.20\n0.01\n-2.21\n0.01\n\n\n1.7\n1.3\n1.3\n1.3\n-1.95\n0.01\n-2.13\n0.03\n-2.20\n0.01\n-2.21\n0.01\n\n\n3.3\n3.3\n3.7\n3.3\n-0.28\n0.27\n-0.13\n0.33\n0.13\n0.45\n-0.21\n0.30\n\n\n3.3\n3.3\n3.7\n3.3\n-0.28\n0.27\n-0.13\n0.33\n0.13\n0.45\n-0.21\n0.30"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#arrange-reorder-observations-in-specific-order",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#arrange-reorder-observations-in-specific-order",
    "title": "Data wrangling in dplyr",
    "section": "arrange: reorder observations in specific order",
    "text": "arrange: reorder observations in specific order\nOrder data by ascending battalion, company, then subnum\n\n\nCode\nunivbct &lt;- univbct %&gt;% \n  arrange(BTN, COMPANY, SUBNUM)\n\n\nDescending sort: descending battalion, ascending company, ascending subnum\n\n\nCode\nunivbct &lt;- univbct %&gt;% \n  arrange(desc(BTN), COMPANY, SUBNUM)"
  },
  {
    "objectID": "materials/w02_wrangling/dplyr_walkthrough.html#a-more-realistic-example-preparation-for-multilevel-analysis",
    "href": "materials/w02_wrangling/dplyr_walkthrough.html#a-more-realistic-example-preparation-for-multilevel-analysis",
    "title": "Data wrangling in dplyr",
    "section": "A more realistic example: preparation for multilevel analysis",
    "text": "A more realistic example: preparation for multilevel analysis\nIn MLM, one strategy for disentangling within- versus between-person effects is to include both within-person-centered variables and person means in the model (Curran & Bauer, 2011).\nWe can achieve this easily for our three DVs here using a single pipeline that combines tidying and mutation. Using -1 as the sep argument to separate splits the string at the second-to-last position (i.e., starting at the right).\nFor reshaping to work smoothly, we need a unique identifier for each row. Also, univbct is stored in a dangerously untidy format in which variables with suffix 1-3 indicate a ‘wide format’, but the data is also in long format under variables such as ‘JSAT’ and ‘COMMIT.’ In other words, there is a peculiar redundancy in the data that is altogether confusing.\nTake a look:\n\n\nCode\nunivbct %&gt;%\n  dplyr::select(SUBNUM, starts_with(\"JOBSAT\"), JSAT) %&gt;% \n  kable_table(n=12)\n\n\n\n\n\n\nSUBNUM\nJOBSAT1\nJOBSAT2\nJOBSAT3\nJSAT\n\n\n\n\n319\n103\n2.0\n2.3\n3.3\n2.0\n\n\n320\n103\n2.0\n2.3\n3.3\n2.3\n\n\n321\n103\n2.0\n2.3\n3.3\n3.3\n\n\n397\n129\n3.7\n4.3\n4.7\n3.7\n\n\n398\n129\n3.7\n4.3\n4.7\n4.3\n\n\n399\n129\n3.7\n4.3\n4.7\n4.7\n\n\n523\n171\n3.7\n4.0\nNA\n3.7\n\n\n524\n171\n3.7\n4.0\nNA\n4.0\n\n\n525\n171\n3.7\n4.0\nNA\nNA\n\n\n616\n202\n1.3\n2.0\n4.3\n1.3\n\n\n617\n202\n1.3\n2.0\n4.3\n2.0\n\n\n618\n202\n1.3\n2.0\n4.3\n4.3\n\n\n\n\n\nWe first need to eliminate this insanity. Group by subject number and retain only the first row (i.e., keep the wide version).\n\n\nCode\nunivbct &lt;- univbct %&gt;% \n  group_by(SUBNUM) %&gt;% # split into separate groups for each subject\n  filter(row_number() == 1) %&gt;% # only retain the first row of each subject\n  dplyr::select(-JSAT, -COMMIT, -READY) %&gt;% # drop redundant columns\n  ungroup() # remove grouping from data structure (we are done with group-based wrangling)\n\n\nFirst, let’s get the data into a conventional format (long) for MLM (e.g., using lmer)\n\n\nCode\nforMLM &lt;- univbct %&gt;% \n  dplyr::select(SUBNUM, JOBSAT1, JOBSAT2, JOBSAT3, \n                COMMIT1, COMMIT2, COMMIT3, \n                READY1, READY2, READY3) %&gt;% \n  \n  # pivot everything but SUBNUM\n  pivot_longer(names_to = \"key\", values_to = \"value\", cols=-SUBNUM) %&gt;%\n  \n  # -1 splits at the last character of the variable name\n  separate(col=\"key\", into=c(\"variable\", \"occasion\"), -1) %&gt;%\n  pivot_wider(names_from = variable, values_from = value) %&gt;% \n  mutate(occasion=as.numeric(occasion))\n\n\nNow, let’s perform the centering described above. You could do this in one pipeline – I just separated things here for conceptual clarity.\n\n\nCode\nforMLM &lt;- forMLM %&gt;% group_by(SUBNUM) %&gt;% \n  mutate(across(c(COMMIT, JOBSAT, READY), list(wic=meancent, pm=mean))) %&gt;%\n  ungroup()\n\nforMLM %&gt;% kable_table(n=10) %&gt;% kable_styling(font_size = 14)\n\n\n\n\n\nSUBNUM\noccasion\nJOBSAT\nCOMMIT\nREADY\nCOMMIT_wic\nCOMMIT_pm\nJOBSAT_wic\nJOBSAT_pm\nREADY_wic\nREADY_pm\n\n\n\n\n103\n1\n2.0\n3.7\n4.0\n0.00\n3.7\n-0.56\n2.6\n1.25\n2.8\n\n\n103\n2\n2.3\n3.7\n2.0\n0.00\n3.7\n-0.22\n2.6\n-0.75\n2.8\n\n\n103\n3\n3.3\n3.7\n2.2\n0.00\n3.7\n0.78\n2.6\n-0.50\n2.8\n\n\n129\n1\n3.7\n5.0\n2.5\n0.44\n4.6\n-0.56\n4.2\n-0.33\n2.8\n\n\n129\n2\n4.3\n4.3\n2.8\n-0.22\n4.6\n0.11\n4.2\n-0.08\n2.8\n\n\n129\n3\n4.7\n4.3\n3.2\n-0.22\n4.6\n0.44\n4.2\n0.42\n2.8\n\n\n171\n1\n3.7\n4.0\n3.2\n-0.17\nNA\n-0.17\nNA\n-0.12\nNA\n\n\n171\n2\n4.0\n4.3\n3.5\n0.17\nNA\n0.17\nNA\n0.12\nNA\n\n\n171\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n202\n1\n1.3\n3.3\n2.5\n0.44\n2.9\n-1.22\n2.6\n-0.75\n3.2"
  },
  {
    "objectID": "materials/w02_wrangling/strings_stringr.html",
    "href": "materials/w02_wrangling/strings_stringr.html",
    "title": "1.4 - Strings in R with stringr",
    "section": "",
    "text": "The stringr package provides a consistent set of functions for working with strings. All functions start with str_ and are vectorized, so they work naturally with columns in a data.frame.\nWe will use a small example dataset to demonstrate the core verbs.\nCode\npeople &lt;- tibble::tibble(\n  id = 1:5,\n  name = c(\"Ada Lovelace\", \"Grace Hopper\", \"Margaret Hamilton\",\n           \"Katherine Johnson\", \"Mary Jackson\"),\n  email = c(\"ada@navy.mil\", \"grace@navy.mil\", \"margaret@mit.edu\",\n            \"katherine@nasa.gov\", NA),\n  dept = c(\"CompSci\", \"CompSci\", \"Engineering\", \"Research\", \"Research\")\n)\n\npeople %&gt;% kable_table()\n\n\n\n\n\nid\nname\nemail\ndept\n\n\n\n\n1\nAda Lovelace\nada@navy.mil\nCompSci\n\n\n2\nGrace Hopper\ngrace@navy.mil\nCompSci\n\n\n3\nMargaret Hamilton\nmargaret@mit.edu\nEngineering\n\n\n4\nKatherine Johnson\nkatherine@nasa.gov\nResearch\n\n\n5\nMary Jackson\nNA\nResearch"
  },
  {
    "objectID": "materials/w02_wrangling/strings_stringr.html#combine-strings",
    "href": "materials/w02_wrangling/strings_stringr.html#combine-strings",
    "title": "1.4 - Strings in R with stringr",
    "section": "Combine strings",
    "text": "Combine strings\n\n\nCode\npeople %&gt;%\n  mutate(\n    label = str_c(name, \" (\", dept, \")\", sep = \"\")\n  ) %&gt;%\n  kable_table()\n\n\n\n\n\nid\nname\nemail\ndept\nlabel\n\n\n\n\n1\nAda Lovelace\nada@navy.mil\nCompSci\nAda Lovelace (CompSci)\n\n\n2\nGrace Hopper\ngrace@navy.mil\nCompSci\nGrace Hopper (CompSci)\n\n\n3\nMargaret Hamilton\nmargaret@mit.edu\nEngineering\nMargaret Hamilton (Engineering)\n\n\n4\nKatherine Johnson\nkatherine@nasa.gov\nResearch\nKatherine Johnson (Research)\n\n\n5\nMary Jackson\nNA\nResearch\nMary Jackson (Research)\n\n\n\n\n\nstr_glue() is convenient for inline formatting:\n\n\nCode\npeople %&gt;%\n  mutate(label = str_glue(\"{name} [{dept}]\")) %&gt;%\n  kable_table()\n\n\n\n\n\nid\nname\nemail\ndept\nlabel\n\n\n\n\n1\nAda Lovelace\nada@navy.mil\nCompSci\nAda Lovelace [CompSci]\n\n\n2\nGrace Hopper\ngrace@navy.mil\nCompSci\nGrace Hopper [CompSci]\n\n\n3\nMargaret Hamilton\nmargaret@mit.edu\nEngineering\nMargaret Hamilton [Engineering]\n\n\n4\nKatherine Johnson\nkatherine@nasa.gov\nResearch\nKatherine Johnson [Research]\n\n\n5\nMary Jackson\nNA\nResearch\nMary Jackson [Research]\n\n\n\n\n\nIf you want to collapse a vector into one string, use str_flatten():\n\n\nCode\nstr_flatten(people$dept, collapse = \", \")\n\n\n[1] \"CompSci, CompSci, Engineering, Research, Research\""
  }
]